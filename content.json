{"meta":{"title":"Welcome!","subtitle":"嘿嘿","description":"就职于不知名小公司，无事来此放放屁","author":"Louis","url":"https://intlouis.github.io","root":"/"},"pages":[{"title":"关于我","date":"2022-03-25T17:45:27.000Z","updated":"2022-03-27T07:39:36.790Z","comments":true,"path":"about/index.html","permalink":"https://intlouis.github.io/about/index.html","excerpt":"","text":"菜鸟一个而已"},{"title":"友链","date":"2022-03-18T01:49:42.000Z","updated":"2022-03-18T01:50:45.199Z","comments":true,"path":"link/index.html","permalink":"https://intlouis.github.io/link/index.html","excerpt":"","text":""},{"title":"分类","date":"2022-03-25T17:40:40.000Z","updated":"2022-03-26T08:01:58.961Z","comments":true,"path":"categories/index.html","permalink":"https://intlouis.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签😄","date":"2022-03-25T17:39:45.000Z","updated":"2022-03-26T08:02:29.473Z","comments":true,"path":"tags/index.html","permalink":"https://intlouis.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"消息中间件（1）——之Kafka","slug":"MQ-kafka","date":"2022-04-23T14:09:45.000Z","updated":"2022-05-09T14:40:25.162Z","comments":true,"path":"2022/04/23/MQ-kafka/","link":"","permalink":"https://intlouis.github.io/2022/04/23/MQ-kafka/","excerpt":"","text":"讲完微服务四大基本组件以后，接下来会发布消息中间件的系列文章，所以第一篇的话选择介绍Kafka。 言归正传 以经典的电商秒杀场景，设想10000件商品在几秒内被秒杀抢购完，我们如何保证在这么短的时间内扛下如此之高的并发，如果机器性能较差，上千甚至上万的QPS直接打在机器上，tomcat线程池一定会被打满，引发生产事故。 此时就需要用到消息中间件，无论有多少请求，统统暂存至MQ，然后服务器慢慢消费，既保证了消息不丢失，也大大减轻了机器的压力。 MQ是高并发场景下常用的中间件，这样的场景一定会依赖MQ，同时MQ也常会用于服务之间的数据同步。 基本术语消息：Kafka 中的数据单元被称为消息，也被称为记录，可以把它看作数据库表中某一行的记录。记录可以是用户发起的http请求。 主题（Topic）：消息的种类称为 主题,可以说一个主题代表了一类消息。相当于是对消息进行分类。主题就像是数据库中的表。 分区（partition）：同一个主题中的分区均匀分布在机器集群，这样可以更好实现服务器集群组的负载均衡。 分区的作用就是让消费者集群中的节点都能消费到同一个topic的消息，假如没有分区，那topicA部署在其中一个节点上，这个节点服务器的压力就会很大，而分区是让消费者集群中都部署topicA，这样消费者就会均匀的把消息发送到每个topicA下。 相当于创建了n个文件夹去存储这些消息。不会把所有的消息都放在一个文件夹里。 生产者（Producer）：MQ中非常重要的概念，向主题（topic）发送消息的就是生产者。 消费者（Consumer）：MQ中非常重要的概念，订阅主题（topic）消息的客户端就是消费者，用于处理生产者产生的消息。 偏移量：偏移量（Consumer Offset）是一种元数据，它是一个不断递增的整数值，用来记录消费者发生重平衡（Rebalance）时的位置，以便用来恢复数据。 broker: 一个独立的 Kafka 服务器就被称为 broker，broker 接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。 broker 集群：broker 是集群 的组成部分，broker 集群由一个或多个 broker 组成，每个集群都有一个 broker 同时充当了集群控制器的角色（自动从集群的活跃成员中选举出来）。 重平衡（Rebalance）：试想，消费组集群中某个实例节点挂掉以后，其他消费者实例自动重新分配topic分区的过程。实现了Kafka的消费端高可用。 Kafka特性高吞吐、低延迟：kakfa 最大的特点就是收发消息非常快，kafka 每秒可以处理几十万条消息，它的最低延迟只有几毫秒。 高伸缩性： 每个主题(topic) 包含多个分区(partition)，主题中的分区可以分布在不同的主机(broker)中。 持久性、可靠性： Kafka 能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失，Kafka 底层的数据存储是基于 Zookeeper 存储的，Zookeeper 我们知道它的数据能够持久存储。 容错性： 允许集群中的节点失败，某个节点宕机，Kafka 集群能够正常工作 高并发： 支持数千个客户端同时读写 Kafka 的消息队列模式 一班消息队列模式分为两种：点对点，发布-订阅者模式。 点对点应该很好理解，就是一个生产者对应一个消费者。 如果是多个生产者对应多个消费者，即生产者集群—消费者集群这样子，就是发布订阅者模式。发布订阅者模式也是设计模式之一，同时也是MQ的核心设计思想之一。 图中所示，一个Kafka集群包含若干个broker、producer、和consumer。 Kafka通过zk管理集群配置，从而选举leader。在consumer发生变化时（例如某个实例挂掉）进行Rebalance。 四个核心APIProducer API，它允许应用程序向一个或多个 topics 上发送消息记录 Consumer API，允许应用程序订阅一个或多个 topics 并处理为其生成的记录流 Streams API，它允许应用程序作为流处理器，从一个或多个主题中消费输入流并为其生成输出流，有效的将输入流转换为输出流。 Connector API，它允许构建和运行将 Kafka 主题连接到现有应用程序或数据系统的可用生产者和消费者 Kafka 为何如此之快 话不多说，Kafka以高性能、高吞吐量、高并发而闻名，下面介绍一下Kafka的零拷贝与批量、顺序写入。 零拷贝广义上的零拷贝，意思就是减少不必要的拷贝次数，并不是真正的不需要拷贝。而减少了不必要的拷贝次数，那就是减少了拷贝次数，提高传输效率，同时也省去了CPU切换上下文的时间。 前景提要：DMA（Direct Memory Access） 直接内存访问（Direct Memory Access），是一种硬件设备绕开CPU独立直接访问内存的机制。所以DMA在一定程度上解放了CPU，把之前CPU的杂活让硬件直接自己做了，提高了CPU效率。 目前支持DMA的硬件包括：网卡、声卡、显卡、磁盘控制器等。 是一种允许外围设备（硬件子系统）直接访问系统主内存的机制。也就是说，基于 DMA 访问方式，系统主内存于硬盘或网卡之间的数据传输可以绕开 CPU 的全程调度。目前大多数的硬件设备，包括磁盘控制器、网卡、显卡以及声卡等都支持 DMA 技术。 只有CPU参与的数据传输时，CPU将参与全局的I/O操作，有不小的上下文切换开销、等待数据读取拷贝时间开销等等。如图： 引入DMA后，CPU将从这些操作中解放出来，这些操作将有DMA来完成，而CPU可以并行地去做别的事情。 这样在大部分时间里，CPU 计算和 I/O 操作都处于并行操作，使整个计算机系统的效率大大提高。 我直接偷一张图来说明应用读写磁盘时，数据拷贝的过程： 图中可知，普通的数据交互，会发生CPU的上下文切换和用户态到内核态的转换。 这样是会对整个数据交互带来一定的开销，一般来说这是正常开销，但在成千上万次数据交互的过程中，这样的开销会占用很大一部分时间。 读数据过程： 应用程序要读取磁盘数据，调用read()函数从而实现用户态切换内核态，这是第1次状态切换； DMA控制器将数据从磁盘拷贝到内核缓冲区，这是第1次DMA拷贝； CPU将数据从内核缓冲区复制到用户缓冲区，这是第1次CPU拷贝； CPU完成拷贝之后，read()函数返回实现用户态切换用户态，这是第2次状态切换； 写数据过程： 应用程序要向网卡写数据，调用write()函数实现用户态切换内核态，这是第1次切换； CPU将用户缓冲区数据拷贝到内核缓冲区，这是第1次CPU拷贝； DMA控制器将数据从内核缓冲区复制到socket缓冲区，这是第1次DMA拷贝； 完成拷贝之后，write()函数返回实现内核态切换用户态，这是第2次切换； 所以有没有一种情况，应用不对数据做处理，那这样还有什么必要进入到应用的缓冲区呢？ 此时，零拷贝出现了。 零拷贝的实现手段，有mmap+write、sendfile、sendfile+DMA收集、splice等，在此着重讲解前二者。 2022.04.25 马不停蹄学习中…… mmapmmap是Linux提供的一种内存映射文件方法。 使用mmap会将内核空间中的读缓冲区（read buffer）的地址，与用户空间（user buffer）进行映射，从而实现内核缓冲区与程序内存的共享。 省去了将数据从内核空间拷贝到用户空间这个开销，但是仍然需要将数据copy到内核的写缓冲区 mmap 主要的用处是提高 I/O 性能，特别是针对大文件。对于小文件，内存映射文件反而会导致碎片空间的浪费，因为内存映射总是要对齐页边界，最小单位是 4 KB，一个 5 KB 的文件将会映射占用 8 KB 内存，也就会浪费 3 KB 内存。 sendfileLinux内核版本2.1中被引入。主要建立了两个文件之间的传输通道。 通过 sendfile 系统调用，数据可以直接在内核空间内部进行 I/O 传输，从而省去了数据在用户空间和内核空间之间的来回拷贝。 与mmap不同的是，对于用户而言，senfile是不可见的，但是可以感知到的。 用户会用senfile而发起数据传输，同时传输结束后会得到结果，但并不知道数据传输的过程，因为senfile不会经历到用户空间。 零拷贝讲了这么多，涉及过多的计算机组成原理和操作系统知识，不明白的同学可以去了解一下这部分的基础。 Kafka消息发送 其消息发送有几种模式，简单消息发送、同步消息发送、异步消息发送。 简单消息发送 代码中生产者(producer)的 send() 方法需要把 ProducerRecord 的对象作为参数进行发送，ProducerRecord 有很多构造函数，这个我们下面讨论， 这里调用的是ProducerRecord，这个构造函数，需要传递的是 topic主题，key 和 value。 1234567ProducerRecord&lt;String,String&gt; record = new ProducerRecord&lt;String, String&gt;(&quot;CustomerCountry&quot;,&quot;West&quot;,&quot;France&quot;);producer.send(record);public ProducerRecord(String topic, K key, V value) &#123;&#125; 从其架构图可知，生产者调用send方法后，会将消息写入分区的缓冲区中，分批次发给 broker。 同步发送消息 同步就不用过多赘述了，就是生产者调用send()消息后，会再调用get()方法等待Kafka响应。如果服务器返回错误，get()方法会抛出异常。 反之，会返回一个RecordMetadata 对象。 生产者（KafkaProducer）在发送的过程中会出现三类错误： 重试错误，这类错误可以通过重发消息来解决。 连接的错误，可以通过再次建立连接来解决； 无主错误则可以通过重新为分区选举首领来解决。 KafkaProducer 被配置为自动重试，如果多次重试后仍无法解决问题，则会抛出重试异常。另一类错误是无法通过重试来解决的，比如消息过大对于这类错误，KafkaProducer 不会进行重试，直接抛出异常。 异步发送消息 同步的弊端不用我多说了吧，发送完必须等待消息返回后才进行下一个消息的发送，效率低下，但是如果你并不关心消息返回值，那用异步发送再合适不过了。 123456789101112ProducerRecord&lt;String, String&gt; producerRecord = new ProducerRecord&lt;String, String&gt;(&quot;CustomerCountry&quot;, &quot;Huston&quot;, &quot;America&quot;); producer.send(producerRecord,new DemoProducerCallBack());//异步回调class DemoProducerCallBack implements Callback &#123; public void onCompletion(RecordMetadata metadata, Exception exception) &#123; if(exception != null)&#123; exception.printStackTrace();; &#125; &#125;&#125; 异步调用的话会有消息回调，如果消息返回了错误，需要手动对错误进行处理。 分区机制 partition代表分区，分区就是topic的分区。即topic会分成若干个区，然后该topic的会使用分区的策略来存储消息。 由于消息是存在主题（topic）的分区（partition）中的，所以当 Producer 生产者发送产生一条消息发给 topic 的时候，你如何判断这条消息会存在哪个分区中呢？ 分区策略分区策略是可以自定义的，详细请参考Kafka官方文档。下面主要介绍几个默认的分区策略。 上图是分区的集群架构，一般来说，Broker集群中每一个broker都有相同的分区，如broker1中有topicA-p0，topicA-p1，topicB-p0，topicB-p1。而这一套分区在Broker2中也有，虎屋 顺序轮询顺序分配，消息是均匀的分配给每个 partition，即每个分区存储一次消息。就像下面这样 顺序轮训策略是 Kafka Producer 提供的默认策略。 按照 key 进行消息保存这个策略也叫做 key-ordering 策略，Kafka 中每条消息都会有自己的key，一旦消息被定义了 Key，那么你就可以保证同一个 Key 的所有消息都进入到相同的分区里面，由于每个分区下的消息处理都是有顺序的，故这个策略被称为按消息键保序策略，如下图所示 闲谈一下，最近工作强度一下子上来了，导致每天都挺累的，不知道是不是工作太认真了😄 关于Kafka集群 系统的高可用、高吞吐必然离不开集群，kafka也是一样的，下面讲述Kafka集群的结构设计。 现在有一个topicA，分成了2个分区，放在三台服务器上。我们知道，主要进行消息读写的是leader分区，所以我们尽量要保证leader均匀分布在各个broker上，这样就算broker宕机后，也不会对Kafka集群的可用性造成很大的冲击。 比如，我们有3个Broker，2个分区分别有2个备份（一共是3组相同的分区），每个分区的leader在一个broker只能有一个，这样保证了集群的高可用。 同时topicB、topicC都遵循这样的原则，这就是集群的意义所在，让服务更加的高可用，提高系统容错性，同时就是需要占用不小的资源。 重平衡当有消费者群组申请加入或者退出的时候，会触发重平衡。 重平衡会将分区均匀分摊给各个消费者（Rebalance），这是Kafka高可用和高伸缩的基础，可以在运行的过程中移除或添加消费者。 但是在重平衡期间，会发生Stop the world（详细参照JVM Full GC），即消费者无法读取到消息，整个消费者会处于不可用的状态。 详细流程在消费者端，重平衡分为两个步骤：分别是加入组和等待领导者消费者（Leader Consumer）分配方案。这两个步骤分别对应两类特定的请求：JoinGroup 请求和 SyncGroup 请求。 当组内成员加入组时，它会向协调者发送 JoinGroup 请求。在该请求中，每个成员都要将自己订阅的主题上报，这样协调者就能收集到所有成员的订阅信息。一旦收集了全部成员的 JoinGroup 请求后，协调者会从这些成员中选择一个担任这个消费者组的领导者。领导者消费者的任务是收集所有成员的订阅信息，然后根据这些信息，制定具体的分区消费分配方案。 选出领导者之后，协调者会把消费者组订阅信息封装进 JoinGroup 请求的响应体中，然后发给领导者，由领导者统一做出分配方案后,领导者向协调者发送 SyncGroup 请求，将刚刚做出的分配方案发给协调者。 其他成员也会向协调者发送 SyncGroup 请求，只不过请求体中并没有实际的内容。这一步的主要目的是让协调者接收分配方案，然后统一以 SyncGroup 响应的方式分发给所有成员，这样组内所有成员就都知道自己该消费哪些分区了。 如下图所示 场景一：新成员加入当协调者收到新的 JoinGroup 请求后，它会通过心跳请求响应的方式通知组内现有的所有成员，强制它们开启新一轮的重平衡。具体的过程和之前的客户端重平衡流程是一样的。 场景二：成员主动离组消费者实例所在线程或进程调用 close() 方法主动通知协调者它要退出。这个场景就涉及到了第三类请求：LeaveGroup 请求。协调者收到 LeaveGroup 请求后，依然会以心跳响应的方式通知其他成员 场景三：组成员崩溃离组他和成员主动离组的区别是它属于被动离开，broker端不知道成员离组，经过心跳超时后，判定成员离组的一种情况。 流程摘自https://juejin.cn/post/6992195021910835230 2022.05.09更新 订阅-发布模式实现Kafka是基于订阅-发布模式，生产者发送消息给Broker，那消费者是如何知道生产者发送了数据呢？ 此处实现订阅-发布者模式，需要消费者定期轮询Kafka Broker，对订阅的topic分区中检索消息，如果有就用来消费，没有就继续轮询下去。 12345678910111213141516try &#123; while (true) &#123; ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(100)); for (ConsumerRecord&lt;String, String&gt; record : records) &#123; int updateCount = 1; if (map.containsKey(record.value())) &#123; updateCount = (int) map.get(record.value() + 1); &#125; map.put(record.value(), updateCount); &#125; &#125;&#125;finally &#123; consumer.close();&#125; 提交和偏移量概念有一个特殊的主题**_consumer_offset**，此主题会保存每次发送消息中分区的偏移量，这个主题主要是防止消息丢失。 当重平衡后，消费者会被重新分配分区，_consumer_offset中记录下重平衡前的最后一次提交的偏移量。 重平衡后，会以上次提交的偏移量位置为起点，进行消费。如图所示，即使当前处理消息为8，但是最后一次提交的偏移量为2，所以重平衡后还是会从2开始消费。 注意，这样可能会导致重复消费，但是同时保证了消息不丢失，只需要做好幂等处理即可。 如果提交的偏移量大于最后一次消费时的偏移量，那么处于两个偏移量中间的消息将会丢失 自动提交如果enable.auto.commit设置为了true，那么默认每过5s，消费者端会自动将轮询拉取下来的消息最大的偏移量提交上去。 自动提交存在的问题： 如果消费并处理完毕，但是还没来得及提交offset，消费者宕机，当消费者重新拉起，就会从上一次提交的offset处进行消费，就会重复消费了。 如果提交了当前最新offset，而消息又没有处理完成，此时消费者又宕机了。但是重新拉起消费者以后，会从最新的offset开始消费，导致宕机前没处理完成的消息丢失。 手动提交手动提交即为处理完成后回调提交，同时手动提交也分为异步提交和同步提交。也可以异步+同步组合的方式提交。 同步提交 手动提交失败后会一直重试，直到重试成功，或者遇到无法重试的情况才结束，这样虽说能够最大限度的保证消息不丢失，但是同时在重试的过程中也阻塞了线程，限制了吞吐量。 手动同步提交应用在对消息丢失容忍度较低的情况下，以此最大限度的额保证消息不丢失。 异步提交 异步提交不会阻塞线程，但同时也不会进行重试，可以配合回调函数在提交失败的时候记录错误信息。 组合提交 对于常规性、阶段性的手动提交，我们调用 commitAsync() 避免程序阻塞，而在 Consumer 要关闭前，我们调用 commitSync() 方法执行同步阻塞式的位移提交，以确保 Consumer 关闭前能够保存正确的位移数据。将两者结合后，我们既实现了异步无阻塞式的位移管理，也确保了 Consumer 位移的正确性。","categories":[{"name":"微服务","slug":"微服务","permalink":"https://intlouis.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"-消息队列 -Kafka","slug":"消息队列-Kafka","permalink":"https://intlouis.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-Kafka/"}]},{"title":"微服务浅谈（四）——限流、熔断之Sentinel","slug":"SpringCloud——限流、熔断之Sentinel","date":"2022-04-07T14:52:06.000Z","updated":"2022-04-16T08:49:23.937Z","comments":true,"path":"2022/04/07/SpringCloud——限流、熔断之Sentinel/","link":"","permalink":"https://intlouis.github.io/2022/04/07/SpringCloud%E2%80%94%E2%80%94%E9%99%90%E6%B5%81%E3%80%81%E7%86%94%E6%96%AD%E4%B9%8BSentinel/","excerpt":"","text":"摆烂了几天，没有更新博客，写博客真是非常耗费脑力的事情。 言归正传，今天介绍SpringCloud的第四大组件——Sentinel 提醒：Sentinel内容比较多嗷~ 服务器雪崩 什么是服务器雪崩？顾名思义，我们知道雪崩可以是很小的波动导致，例如你对着雪山大吼一声，也有可能导致雪崩。 类比到系统中，一个很小的“波动”，例如有一条sql是慢查询，假设这样一个场景，你的系统重启完毕，大量用户涌入，每个用户都会调用到这个存在慢查询的接口，那这一下会将tomcat线程全部打满，导致所有的线程全部hold住，其他接口无法创建请求，整个系统处于崩溃状态。 这就是由于慢查询导致的雪崩。 在微服务中，当一个服务A不可用，会造成调用A服务的服务也发生大量线程hold住，形成连锁效应，导致整个微服务系统崩坏。 雪崩对于客户端也是可感知的，当客户端发起请求后，迟迟得不到返回结果，这就是客户端的雪崩表现。原因就是线程池已经爆满，或者接近爆满。 当然，在实际生产环境中，导致雪崩的原因有很多，为了防止雪崩，我们引入Sentinel对流量过大的接口进行熔断。 Sentinel实质上是给予了系统更大的容错性，即使服务发生故障，也可以及时地切断服务调用链路或进行降级，这样一定程度的保证了系统的高可用，增强系统的健壮性。 对商用系统而言，系统宕机是非常严重的事故，基本都是在P1级别起步，宕机过程中不仅存在数据丢失，损失更是按照秒来计算，所以系统容错是非常重要的，宁愿服务部分可用，也不能完全挂掉。 解决方案常见的容错思路有隔离、超时、限流、熔断、降级这几种。 隔离非常容易理解，假设服务A有100个线程，我们各分配30个给B、C、D服务，即使其中一个或多个服务宕机，也不会影响其他服务的调用。 超时 在上游服务调用下游服务的时候，设置一个最大响应时间，如果超过这个时间，下游未作出反应，就断开请求，释放掉线程。 但是超时时间需要斟酌设置，如果设置过大，也容易产生线程堆积。如果设置过小，则有些请求正常执行，却返回稍慢，导致请求被中断，数据无法返回，造成用户体验下降。 限流 限流，就是限制系统流量，包含进入系统的流量以及输出的流量，当流量打到设置的阈值，就需要开启相应的限流措施，在下面会详细讲到。 熔断 熔断机制是一种级别较高的保证系统高可用的无奈之举，当下游的系统因为某种原因导致服务器压力过大导致的响应变慢，此时上游系统继续调用该系统容易导致下游系统的雪崩效应，进而可能导致整个系统崩溃。 所以熔断就出现了：暂时停止对下游系统的调用。这样保证了当前系统的高可用，但是存在了局部不可用，这就是牺牲局部保全整体的措施。 服务熔断一般有三种状态： 熔断关闭状态（Closed）：服务没有故障时，熔断器所处的状态，对调用方的调用不做任何限制。 熔断开启状态（Open）：后续对该服务接口的调用不再经过网络，直接执行本地的fallback方法。 半熔断状态（Half-Open）：尝试恢复服务调用，允许有限的流量调用该服务，并监控调用成功率。如果成功率达到预期，则说明服务已恢复，进入熔断关闭状态；如果成功率仍旧很低，则重新进入熔断关闭状态。 降级 降级其实就是为服务提供一个兜底方案，一旦服务无法正常调用，就使用兜底方案。 比如当前服务不可用了，那我就切换到备用节点等等。 Sentinel各种相关规则 Sentinel的各种相关规则是实现精细化系统高可用的基础。 细颗粒的规则制定可以让系统的高可用更加灵活，让系统故障影响范围缩减至尽可能小。 Sentinel流量控制规则首先流控是以资源为单位，即接口请求地址。 流量控制，原理是监控当前资源QPS或并发线程数指标，避免被突发流量冲击系统造成系统波动。保证系统的高可用。 资源名：唯一名称，默认是请求路径，可自定义。 针对来源：指定对哪个微服务进行限流，默认指default，意思是不区分来源，全部限制。 阈值类型/单机阈值： QPS（每秒请求数量）: 当调用该接口的QPS达到阈值的时候，进行限流。 线程数：当调用该接口的线程数达到阈值的时候，进行限流。 关联流控模式某些资源存在争抢现象，例如两个接口修改同一个字段，抢占资源只会降低系统吞吐量，所以需要施加流控。 关联流控模式指的是，当指定接口关联的接口达到限流条件时，开启对指定接口开启限流。 链路流控模式对调用资源的链路进行监控，比如 1.在OrderService中添加一个queryGoods方法，不用实现业务2.在OrderController中，改造/order/query端点，调用OrderService中的queryGoods方法(/order/query -&gt; queryGoods)3.在OrderController中添加一个/order/save的端点，调用OrderService的queryGoods方法(/order/save -&gt; queryGoods) 两者都是调用queryGoods这个方法，但是可以监控其中一个调用链路，当调用链路达到阈值，则对该链路进行流控。 流控效果 快速失败（默认）: 直接失败，抛出异常，不做任何额外的处理，是最简单的效果。 Warm Up：它从开始阈值到最大QPS阈值会有一个缓冲阶段，一开始的阈值是最大QPS阈值的 1/3，然后慢慢增长，直到最大阈值，适用于将突然增大的流量转换为缓步增长的场景。 排队等待：让请求以均匀的速度通过，单机阈值为每秒通过数量，其余的排队等待； 它还会让设 置一个超时时间，当请求超过超时间时间还未处理，则会被丢弃。 Sentinel降级规则 降级规则有三个衡量指标，慢调用比例、异常响应比例、异常数。 慢调用比例: 选择以慢调用比例作为阈值，需要设置允许的慢调用 RT（即最大的响应时间），请求的响应时间大于该值则统计为慢调用。当单位统计时长内请求数目大于设置的最小请求数目，并且慢调用的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求响应时间小于设置的慢调用 RT 则结束熔断，若大于设置的慢调用 RT 则会再次被熔断。 探测恢复状态（HALF-OPEN 状态）：在此状态下，在接下来的设置的时间之内都不会调用真实方法，直接走降级方法。 异常比例: 当单位统计时长内请求数目大于设置的最小请求数目，并且异常的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。异常比率的阈值范围是 [0.0, 1.0]，代表 0% - 100%。 异常数：当单位统计时长内的异常数目超过阈值之后会自动进行熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断 如图所示： 上面配置表示，如果在1S之内,有【超过1个的请求】且这些请求中【响应时间&gt;最大RT】的【请求数量比例&gt;10%】，就会触发熔断。 比如: 最大RT=900,比例阈值=0.1,熔断时长=10,最小请求数=10 情况1: 1秒内的有20个请求，只有10个请求响应时间&gt;900ms, 那慢调用比例=0.5，这种情况就会触发熔断。 情况2: 1秒内的有20个请求，只有1个请求响应时间&gt;900ms, 那慢调用比例=0.05，这种情况不会触发熔断。 情况3: 1秒内的有8个请求，只有6个请求响应时间&gt;900ms, 那慢调用比例=0.75，这种情况不会触发熔断，因为最小请求数这个条件没有满足。 Sentinel热点规则Sentinel还可以对热点数据数据进行监控和限流，比如某个接口的订单参数调用量特别容易突发增长。 1234567891011@RestController@Slf4jpublic class HotSpotController &#123; @RequestMapping(&quot;/hotSpot1&quot;) @SentinelResource(value = &quot;hotSpot1&quot;) public String hotSpot1(Long productId)&#123; log.info(&quot;访问编号为:&#123;&#125;的商品&quot;,productId); return &quot;hotSpot1&quot;; &#125;&#125; 新增一个热点规则：如图意义为监控hotSpot1这个接口的请求情况。 因为我们就一个参数，所以参数索引是0。 新增规则参数，热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流。热点参数限流可以看做是一种特殊的流量控制，仅对包含热点参数的资源调用生效。 请求过来时，请求中的第一个参数，即productId = 1的时候，定义为了热点信息，热点信息超过阈值时，则会被限流。 系统规则 系统保护规则是从应用级别的入口流量进行控制，从单台机器的总体 Load、RT、入口 QPS 、CPU使用率和线程数五个维度监控应用数据，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 系统保护规则是应用整体维度的，而不是资源维度的，并且仅对入口流量 (进入应用的流量) 生效。 Load（仅对 Linux/Unix-like 机器生效）：当系统 load1 超过阈值，且系统当前的并发线程数超过系统容量时才会触发。 系统保护。系统容量由系统的 maxQps * minRt 计算得出。设定参考值一般是 CPU cores * 2.5。 RT：当单台机器上所有入口流量的平均 RT 达到阈值即触发系统保护，单位是毫秒。 线程数：当单台机器上所有入口流量的并发线程数达到阈值即触发系统保护。 入口 QPS：当单台机器上所有入口流量的 QPS 达到阈值即触发系统保护。 CPU使用率：当单台机器上所有入口流量的 CPU使用率达到阈值即触发系统保护。 Sentinel规则持久化我们知道，这些规则是存储在内存中的。一旦服务器重启，就会消失，所以持久化我们的自定义规则，应该都是基本操作。 这个Sentinel Dashboard类似控制台，就是我们操作的可视化界面。 如图所示为Sentinel持久化规则的流程图。 @SentinelResource的使用 @SentinelResource 用于定义资源，并提供可选的异常处理和 fallback 配置项。主要参数如下： 属性 作用 value 资源名称，必需项（不能为空） entryType entry 类型，可选项（默认为 EntryType.OUT） blockHandler/blockHandlerClass blockHandler 对应处理 BlockException 的函数名称，可选项。blockHandler 函数访问范围需要是 public，返回类型需要与原方法相匹配，参数类型需要和原方法相匹配并且最后加一个额外的参数，类型为 BlockException。blockHandler 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 blockHandlerClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。 fallback/fallbackClass fallback 函数名称，可选项，用于在抛出异常的时候提供 fallback 处理逻辑。fallback 函数可以针对所有类型的异常（除了 exceptionsToIgnore 里面排除掉的异常类型）进行处理。fallback 函数签名和位置要求： 1. 返回值类型必须与原函数返回值类型一致； 2.方法参数列表需要和原函数一致，或者可以额外多一个 Throwable 类型的参数用于接收对应的异常。 3.fallback 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 fallbackClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。 defaultFallback 默认的 fallback 函数名称，可选项，通常用于通用的 fallback 逻辑（即可以用于很多服务或方法）。默认 fallback 函数可以针对所有类型的异常（除了 exceptionsToIgnore 里面排除掉的异常类型）进行处理。若同时配置了 fallback 和 defaultFallback，则只有 fallback 会生效。defaultFallback 函数签名要求： 1. 返回值类型必须与原函数返回值类型一致； 2. 方法参数列表需要为空，或者可以额外多一个 Throwable 类型的参数用于接收对应的异常。 3. defaultFallback 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 fallbackClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。 exceptionsToIgnore 用于指定哪些异常被排除掉，不会计入异常统计中，也不会进入 fallback 逻辑中，而是会原样抛出。 Sentinel是默认与MVC兼容的，也就是说普通的的接口是默认会接入监控的，但一些其他方法，不是通过Controller进行调用的资源。你也想监控此类资源，则需要加上SentinelResource进行监控。 Sentinel的总结到这里就告一段落，微服务四大主要组件都已分享完毕，后面会更新一些生产问题的处理过程、思考过程。不过也不一定嘿嘿嘿，🤭","categories":[],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://intlouis.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://intlouis.github.io/tags/SpringCloud/"},{"name":"Sentinel","slug":"Sentinel","permalink":"https://intlouis.github.io/tags/Sentinel/"}]},{"title":"微服务浅谈（三）——Gateway网关","slug":"SpringCloud-网关","date":"2022-03-27T16:39:32.000Z","updated":"2022-04-07T14:53:18.460Z","comments":true,"path":"2022/03/28/SpringCloud-网关/","link":"","permalink":"https://intlouis.github.io/2022/03/28/SpringCloud-%E7%BD%91%E5%85%B3/","excerpt":"","text":"所有请求必经之门——网关Nginx与Gateway的区别SpringCloud Gateway作为网关，其作用和Nginx是有区别的。 1、Gateway和Nginx可以取其一进行使用，也可以两个都使用，具体是看系统结构和业务需求，这个很重要。 2、Gateway更加贴近业务层面，因为它可以在截到请求后执行一些鉴权、过滤、断言等，做一些基本的流控。 3、Nginx更多是作为流量的总入口，负载均衡等。 4、Nginx支持Lua脚本，但是其始终是需要进行二次开发，扩展性不如Gateway。 SpringCloud Gateway 更加靠近业务。 假设系统结构是： Ng-&gt;Gateway-&gt;业务层，那么Ng只是作为一个流量入口的作用，并没有接触到业务。而Gateway可以将请求路由到服务端（某一微服务）。 Gateway 可以与Nacos集成，通过拉取Nacos中注册中心的地址，通过拉取到的地址进行转发，这样避免了将请求地址写死在配置中。同时，也会在转发请求的时候遵循你设置好的Ribbon负载均衡策略。 Gateway几个基本信息 id：路由标识符，区别于其他 Route。 uri：路由指向的目的地 uri，即客户端请求最终被转发到的微服务。 order：用于多个 Route 之间的排序，数值越小排序越靠前，匹配优先级越高。 predicate：断言的作用是进行条件判断，只有断言都返回真，才会真正的执行路由。 filter：过滤器用于修改请求和响应信息。 predicate：断言，用于进行条件判断，只有断言都返回真，才会真正的执行路由。 将这几个参数理解即可，会在配置文件中使用到。 过滤器过滤器的生命周期： 1、PRE：这种过滤器会在请求被路由前，即转发请求前会执行过滤器中编写的逻辑代码。我们一般会用这种过滤器进行身份验证、挑选服务实例、日志追踪、请求者信息记录等等。 2、POST：这种过滤器会在请求路由到服务后，执行相应逻辑代码。这种过滤器可用来为响应添加标准的HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等。 两种Filter：GatewayFilter与GlobalFilter，顾名思义，一个是局部过滤，一个是全局过滤。 局部过滤器局部过滤器提供的API的功能一般来说可以满足大部分的需求了： 过滤器工厂 作用 参数 AddRequestHeader 为原始请求添加Header Header的名称及值 AddRequestParameter 为原始请求添加请求参数 参数名称及值 AddResponseHeader 为原始响应添加Header Header的名称及值 DedupeResponseHeader 剔除响应头中重复的值 需要去重的Header名称及去重策略 Hystrix 为路由引入Hystrix的断路器保护 HystrixCommand 的名称 FallbackHeaders 为fallbackUri的请求头中添加具体的异常信息 Header的名称 PrefixPath 为原始请求路径添加前缀 前缀路径 PreserveHostHeader 为请求添加一个preserveHostHeader=true的属性，路由过滤器会检查该属性以决定是否要发送原始的Host 无 RequestRateLimiter 用于对请求限流，限流算法为令牌桶 keyResolver、 rateLimiter、 statusCode、 denyEmptyKey、 emptyKeyStatus RedirectTo 将原始请求重定向到指定的URL http状态码及重定向的url RemoveHopByHopHeadersFilter 为原始请求删除IETF组织规定的一系列Header 默认就会启用，可以通过配置指定仅删除哪些Header RemoveRequestHeader 为原始请求删除某个Header Header名称 RemoveResponseHeader 为原始响应删除某个Header Header名称 RewritePath 重写原始的请求路径 原始路径正则表达式以及重写后路径的正则表达式 RewriteResponseHeader 重写原始响应中的某个Header Header名称，值的正则表达式，重写后的值 SaveSession 在转发请求之前，强制执行WebSession::save操作 无 secureHeaders 为原始响应添加一系列起安全作用的响应头 无，支持修改这些安全响应头的值 SetPath 修改原始的请求路径 修改后的路径 SetResponseHeader 修改原始响应中某个Header的值 Header名称，修改后的值 SetStatus 修改原始响应的状态码 HTTP 状态码，可以是数字，也可以是字符串 StripPrefix 用于截断原始请求的路径 使用数字表示要截断的路径的数量 Retry 针对不同的响应进行重试 retries、statuses、methods、series RequestSize 设置允许接收最大请求包的大小。如果请求包大小超过设置的值，则返回 413 Payload Too Large 请求包大小，单位为字节，默认值为5M ModifyRequestBody 在转发请求之前修改原始请求体内容 修改后的请求体内容 ModifyResponseBody 修改原始响应体的内容 修改后的响应体内容 自定义局部过滤器 自定义局部过滤器很好理解，相信各位都写过拦截用户请求进行鉴权的拦截器，网关其实也是这么一个原理，只不过网关远远比我们自己写的拦截器功能更加丰富。 重点：名称是有固定格式【xxxGatewayFilterFactory】，这个很重要，关系到后面的配置类中的编写。 举例，我要打印每个接口的耗时： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@Componentpublic class TimeGatewayFilterFactory extends AbstractGatewayFilterFactory&lt;TimeGatewayFilterFactory.Config&gt; &#123; private static final String BEGIN_TIME = &quot;beginTime&quot;; //构造函数 public TimeGatewayFilterFactory() &#123; super(TimeGatewayFilterFactory.Config.class); &#125; //读取配置文件中的参数 赋值到 配置类中 @Override public List&lt;String&gt; shortcutFieldOrder() &#123; return Arrays.asList(&quot;show&quot;); &#125; @Override public GatewayFilter apply(Config config) &#123; return new GatewayFilter() &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; if (!config.show)&#123; // 如果配置类中的show为false，表示放行 return chain.filter(exchange); &#125; exchange.getAttributes().put(BEGIN_TIME, System.currentTimeMillis()); /** * pre的逻辑 * chain.filter().then(Mono.fromRunable(()-&gt;&#123; * post的逻辑 * &#125;)) */ return chain.filter(exchange).then(Mono.fromRunnable(()-&gt;&#123; Long startTime = exchange.getAttribute(BEGIN_TIME); if (startTime != null) &#123; System.out.println(exchange.getRequest().getURI() + &quot;请求耗时: &quot; + (System.currentTimeMillis() - startTime) + &quot;ms&quot;); &#125; &#125;)); &#125; &#125;; &#125; @Setter @Getter static class Config&#123; private boolean show; &#125;&#125; 配置文件如下，因为我们的逻辑类名是TimeGatewayFilterFactory 所以其配置key就是Time=true/false，本例子转载于掘金大佬博客 1234567891011121314151617181920212223242526272829server: port: 9000spring: application: name: api-gateway cloud: nacos: discovery: server-addr: 127.0.0.1:8848 gateway: discovery: locator: enabled: true # 让gateway可以发现nacos中的微服务 routes: - id: product_route # 路由的名字 uri: lb://product-service # lb指的是从nacos中按照名称获取微服务,并遵循负载均衡策略 predicates: - Path=/product-serv/** # 符合这个规定的才进行1转发 filters: - StripPrefix=1 # 将第一层去掉 - id: order_route uri: lb://order-service predicates: - Path=/order-serv/** filters: - StripPrefix=1 - Time=true 全局过滤全局过滤，只需集成GlobalFilter即可编写自定义逻辑代码，无需其余的配置。 123456789101112131415@Componentpublic class AuthGlobalFilter implements GlobalFilter &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; String token = exchange.getRequest().getQueryParams().getFirst(&quot;token&quot;); if (StringUtils.isBlank(token)) &#123; System.out.println(&quot;鉴权失败&quot;); exchange.getResponse().setStatusCode(HttpStatus.UNAUTHORIZED); return exchange.getResponse().setComplete(); &#125; return chain.filter(exchange); &#125;&#125; 除此之外默认有几种全局过滤器。 2022/03/31补充： 通过与明新讨论，Gateway的吞吐量优化，自己上网查阅部分资料，补充以下内容： 常见的限流算法1、计数器算法 这个算法很好理解，设定一个阈值，如K = 100，则在单位时间内，超过这个阈值的请求全部都将被拒绝。 这个算法很粗暴，个人觉得没有什么应用价值，因为其存在很大的弊端，举例： 如果我设定，一分钟内只能通过500的请求，可以认为服务器在一分钟内最多能处理500请求。 那么存在两个周期的零界点，就是这一分钟的请求在前55秒处理了100个请求，剩下400个请求集中在最后5秒，如果下一个一分钟的前5秒，又迎来400个请求，那么这10秒钟就处理了800个请求，远远超出了服务器单位时间内所能承受的最大请求数。 结论就是，计数器算法并不适合应对突发的峰值流量。 2、漏桶算法 漏桶算法，顾名思义，就是给桶的底部戳一个洞，这个洞漏出去水的速率是均匀的。 请求进来相当于给这个漏桶加水，无论桶里的水有多少，漏出去水的速率都是均匀的，但存在一个问题，就是水满自溢。 同时，其优势就是能够保护数据库，不让突发而来的请求全部打在db上。 但是短板也显而易见，桶的容量始终是固定的，如果到存在请求洪峰，那将会有大量的请求被”溢出“。 3、令牌桶算法 此算法是结合了漏桶算法升级而来，当请求进来，拿到令牌时才能继续往下执行。 当加入令牌的速率恒定，在请求速率较小时（低于令牌生产的速度），此时令牌可以积累一部分的令牌，从而应对突发的洪峰请求。 但是令牌也不是生产的，当令牌桶满了，生产的令牌也会被丢弃。从而最大程度的处理请求，也很好的保护了DB。 网关集成Sentinel本部分会在后续的Sentinel文章中详细讲解。","categories":[{"name":"微服务","slug":"微服务","permalink":"https://intlouis.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://intlouis.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://intlouis.github.io/tags/SpringCloud/"},{"name":"gateway","slug":"gateway","permalink":"https://intlouis.github.io/tags/gateway/"},{"name":"限流算法","slug":"限流算法","permalink":"https://intlouis.github.io/tags/%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95/"}]},{"title":"微服务浅谈（二）——服务调用&OpenFeign","slug":"SpringCloud-OpenFeign","date":"2022-03-14T16:41:15.000Z","updated":"2022-03-27T16:41:01.182Z","comments":true,"path":"2022/03/15/SpringCloud-OpenFeign/","link":"","permalink":"https://intlouis.github.io/2022/03/15/SpringCloud-OpenFeign/","excerpt":"","text":"服务调用的两种常用方式：RPC&amp;HTTPHTTP就不过多介绍了，稍微讲一下RPC的架构。 RPC架构一个完整的RPC架构里面包含了四个核心的组件，分别是Client，Client Stub，Server以及Server Stub，这个Stub可以理解为存根。 客户端(Client)，服务的调用方。 客户端存根(Client Stub)，存放服务端的地址消息，再将客户端的请求参数打包成网络消息，然后通过网络远程发送给服务方。 服务端(Server)，真正的服务提供者。 服务端存根(Server Stub)，接收客户端发送过来的消息，将消息解包，并调用本地的方法。 纵观整个过程，实际上就是客户端发起调用，然后本次调用经过Client Stub封装，发送给Server，然后Server Stub会解析发送过来的内容，并且将数据进行返回。 RPC的目标就是要把2、3、4、7、8、9这些步骤都封装起来。 RPC调用是使用自定义的数据格式进行传输，是基于原生TCP进行通信，速度较快，效率较高。 HTTP则是一种较为通用的调用方式，在跨语言上存在优势，只要提供restful风格的接口，则可以进行请求。 关于RPC与Http的技术选型：如果需要使用RPC调用，则需要服务提供方与消费方都是使用RPC调用，即需要双方使用相同的技术，如都使用Dubbo调用。 而Http则无需关注语言的实现，只需请求数据遵循restful规范即可。 如何选择？ 既然两种方式都可以实现远程调用，我们该如何选择呢？ 速度来看，RPC要比http更快，虽然底层都是TCP，但是http协议的信息往往比较臃肿 难度来看，RPC实现较为复杂，http相对比较简单 灵活性来看，http更胜一筹，因为它不关心实现细节，跨平台、跨语言。 因此，两者都有不同的使用场景： 如果对效率要求更高，并且开发过程使用统一的技术栈，那么用RPC还是不错的。 如果需要更加灵活，跨语言、跨平台，显然http更合适 那么我们该怎么选择呢？ 微服务，更加强调的是独立、自治、灵活。而RPC方式的限制较多，因此微服务框架中，一般都会采用基于Http的Rest风格服务。 RestTemplate存在的问题其实Rest存在的问题，只需要三个字概况，不够优雅（四个字），当调用服务的url拼接较多的参数时，这样的url会变得非常难以维护，这样拼接的url在实际生产中并不少见。 OpenFeign简介OpenFeign是一种可以在微服务之间实现“无感知调用“的一个中间件。 即引入这种中间件以后，各个接口之间的调用就像在单机上部署一样，无需过多的关注调用的地址和端口，这就是所谓的”无感知调用“，或许这样描述并不是非常恰当，但达意即可。 SpringMVC的注解，如@RequestMapping等等。OpenFeign的@FeignClient可以解析SpringMVC的@RequestMapping注解下的接口，并通过动态代理的方式产生实现类，实现类中做负载均衡并调用其他服务。 OpenFeign沿用SpringMVC的注解，大大地降低了学习成本，作为一个组件它是一个好组件😀 OpenFeign的底层还是使用了Ribbon，Ribbon的介绍在博客相关文章有介绍过，所以OpenFeign是一个调用+客户端负载均衡的一个微服务组件。 OpenFeign把RestTemplete，Ribbon，Hystrix糅合在了一起，在使用时就可以更加方便，优雅地完成整个服务的暴露，调用等。避免做一些重复的复制粘贴接口URL，或者重复定义接口等。还是非常值得去学习的。 但Hystrix一般由Sentinel代替了，关于Sentinel的博客文章后续会发布。 OpenFeign的简单使用 1、在启动类上增加@EnableFeignClients注解（注：以下例子来自OpenFeign官方文档） 1234567891011121314@SpringBootApplication@EnableFeignClientspublic class WebApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(WebApplication.class, args); &#125; @FeignClient(&quot;name&quot;) static interface NameService &#123; @RequestMapping(&quot;/&quot;) public String getName(); &#125;&#125; 2、StoreClient就是供消费者调用的接口，每个接口上添加MVC相应注解以及接口请求地址。一般来说会专门创建一个这样的interface以供消费者调用。 1234567891011121314@FeignClient(&quot;stores&quot;)public interface StoreClient &#123; @RequestMapping(method = RequestMethod.GET, value = &quot;/stores&quot;) List&lt;Store&gt; getStores(); @RequestMapping(method = RequestMethod.GET, value = &quot;/stores&quot;) Page&lt;Store&gt; getStores(Pageable pageable); @RequestMapping(method = RequestMethod.POST, value = &quot;/stores/&#123;storeId&#125;&quot;, consumes = &quot;application/json&quot;) Store update(@PathVariable(&quot;storeId&quot;) Long storeId, Store store); @RequestMapping(method = RequestMethod.DELETE, value = &quot;/stores/&#123;storeId:\\\\d+&#125;&quot;) void delete(@PathVariable Long storeId);&#125; 3、在消费者的Controller层，注入StoreClient这个对象，使用这个对象直接进行方法调用即可。 Feign的自定义配置日志级别： NONE：不打印任何日志。 BASIC：只记录请求方法、URL、响应状态码和执行时间 HEADERS：记录基本信息，请求和响应标题 FULL： 记录请求和响应标题、正文和行数据 还有其他的Feign自定义配置，在此就不一一赘述。","categories":[{"name":"微服务","slug":"微服务","permalink":"https://intlouis.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"OpenFeign","slug":"OpenFeign","permalink":"https://intlouis.github.io/tags/OpenFeign/"},{"name":"微服务","slug":"微服务","permalink":"https://intlouis.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://intlouis.github.io/tags/SpringCloud/"}]},{"title":"微服务浅谈（一）——Nacos","slug":"SpringCloud_Nacos","date":"2022-03-13T11:31:08.440Z","updated":"2022-03-25T18:12:30.809Z","comments":true,"path":"2022/03/13/SpringCloud_Nacos/","link":"","permalink":"https://intlouis.github.io/2022/03/13/SpringCloud_Nacos/","excerpt":"","text":"服务注册中心注册中心基本原理 在使用注册中心时，一共有三种角色：服务提供者（Service Provider）、服务消费者（Service Consumer）、注册中心（Registry）。 服务发现原理：服务发现机制就是通过一个中间件去记录服务提供者的ip地址，服务名以及心跳等数据（比如用mysql去存储这些信息），然后服务消费者会去这个中间平台去查询相关信息，然后再去访问对应的地址，这就是服务注册和服务发现。 Nacos 提供对服务的实时的健康检查，阻止向不健康的主机或服务实例发送请求。Nacos 支持传输层 (PING 或 TCP)和应用层 (如 HTTP、MySQL、用户自定义）的健康检查。 对于复杂的云环境和网络拓扑环境中（如 VPC、边缘网络等）服务的健康检查，Nacos 提供了 agent 上报模式和服务端主动检测2种健康检查模式。Nacos 还提供了统一的健康检查仪表盘，帮助您根据健康状态管理服务的可用性及流量。 服务提供者：向注册中心注册为一个服务实例，并且向外部暴露调用接口。 服务消费者：向注册中心订阅需要调用的服务，并缓存服务的实例列表再内存中。后续，Consumer 向对应服务的 Provider 发起调用时，从内存中的该服务的实例列表选择一个，进行远程调用。 注册中心：当注册的实例超过一定时间未心跳（nacos默认30s心跳一次，若下一次未收到，将不再路由请求至该实例），则注册中心判断这个服务已下线，将从服务实例列表移除。 不同的注册中心可能在实现原理上会略有差异。例如说，Eureka 注册中心，并不提供通知功能，而是 Eureka Client 自己定期轮询，实现本地缓存的更新。 当然，一个服务消费者，也可以是一个服务提供者。 nacos 作为注册中心时，Namespace + Group + Service 作为配置中心时，Namespace + Group + DataId 元数据： Nacos数据（如配置和服务）描述信息，如服务版本、权重、容灾策略、负载均衡策略、鉴权配置、各种自定义标签（label），从作用范围来看，分为服务级别的元信息、集群的元信息及实例的元信息。 Nacos1.x与Nacos2.xNacos1.x对比存在的问题 1、心跳续约是30s（默认），当服务较多时，就会有较高的TPS数。 2、心跳感知问题，心跳感知为15s无应答，即15秒未感知到应用心跳时，才能删除实例，在并发较高的情况下，降低服务的高可用。如：当服务宕机时，需要快速剔除服务实例，但需要等待15s，这样的时效性并不理想。 3、有HTTP和UDP两种数据推送的方式，与客户端需要进行全量对账（保持服务发现），会进行大量查询，导致QPS较高，这种可以理解成牺牲大量的查询来保持服务的发现，但实际生产中，所有的服务都是较为稳定的，大量的查询实际是为了那仅有的几个服务变动而设计，这样的性价比并不高。 Nacos2.x优化 1、使用长连接进行心跳续约，大大降低重复请求。同时长连接在断开时是可以快速感知到的，不需要等待15s。 2、连接反复创建存在开销，使用长连接减少了这样的开销，同时减少了TIME_WAIT的问题。 2.0架构带来的问题 相对于Tomcat HTTP短连接模型，长连接模型需要自己管理连接状态，增加了复杂性 长连接gRPC基于HTTP2.0 Stream，相对于HTTP的open API可观测性和易用性降低了 两者性能对比 具体性能分析可参照这篇博文：重磅官宣：Nacos2.0 发布，性能提升 10 倍 负载均衡服务器端负载均衡： 由中间件Ng进行路由 客户端负载均衡： 根据负载均衡规则，自行请求。 Ribbon：提供丰富的负载均衡算法。 手写一个客户端侧负载均衡器 手写负载均衡器部分代码如图： 这段代码的意思就是在实例列表中随机进行请求。这段代码只是粗略展示负载均衡的其中一个算法。 手写负载均衡器主要原理就是获取到此服务的所有url，然后以轮询、随机等方式进行调用指定的url Ribbon与Nginx的区别既然提到了负载均衡，怎么能少得了Nginx呢，Ribbon和Nginx之间的不同在于，Nginx是集中式的对接收的请求进行负载均衡，而Ribbon是在消费者端进行负载均衡，形象一点就是如下图。 NginxNginx的工作模型如下图： RibbonRibbon的工作模型如下图 Ribbon的负载均衡与Ng的负载均衡之不同就是，Ng是被动负载均衡，Ribbon是主动负载均衡。 Ribbon会在收到Http请求后，去拉取注册中心中的服务实例List，获取到List以后，会使用负载均衡策略，在List中挑选一个服务实例进行请求。 Ribbon默认是懒加载，懒加载会使项目启动速度加快，但是同时在第一次请求时，会去拉取注册中心的服务实例，以及初始化负载均衡容器，导致请求响应速度相对较慢。同时可选定服务进行配置饥饿加载。 同时Ribbon有多种负载均衡的策略模式可供选择，默认的就是同区域轮训模式：ZoneAwareLoadBalancer 是一个根据区域（Zone） 来进行负载均衡器，因为如果不同机房跨区域部署服务列表，跨区域的方式访问会产生更高的延迟，ZoneAwareLoadBalancer 就是为了解决此类问题，不过默认都是同一区域 Ribbon负载均衡策略： 策略类 命名 描述 RandomRule 随机策略 随机选择server RoundRobinRule 轮询策略 轮询选择， 轮询index，选择index对应位置的Server； RetryRule 重试策略 对选定的负载均衡策略机上重试机制，在一个配置时间段内当选择Server不成功，则一直尝试使用subRule的方式选择一个可用的server； BestAvailableRule 最低并发策略 逐个考察server，如果server断路器打开，则忽略，再选择其中并发链接最低的server AvailabilityFilteringRule 可用过滤策略 过滤掉一直失败并被标记为circuit tripped的server，过滤掉那些高并发链接的server（active connections超过配置的阈值）或者使用一个AvailabilityPredicate来包含过滤server的逻辑，其实就就是检查status里记录的各个Server的运行状态； ResponseTimeWeightedRule 响应时间加权重策略 根据server的响应时间分配权重，响应时间越长，权重越低，被选择到的概率也就越低。响应时间越短，权重越高，被选中的概率越高，这个策略很贴切，综合了各种因素，比如：网络，磁盘，io等，都直接影响响应时间 ZoneAvoidanceRule 区域权重策略 综合判断server所在区域的性能，和server的可用性，轮询选择server并且判断一个AWS Zone的运行性能是否可用，剔除不可用的Zone中的所有server","categories":[{"name":"微服务","slug":"微服务","permalink":"https://intlouis.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://intlouis.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://intlouis.github.io/tags/SpringCloud/"},{"name":"Nacos","slug":"Nacos","permalink":"https://intlouis.github.io/tags/Nacos/"}]}],"categories":[{"name":"微服务","slug":"微服务","permalink":"https://intlouis.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"-消息队列 -Kafka","slug":"消息队列-Kafka","permalink":"https://intlouis.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-Kafka/"},{"name":"微服务","slug":"微服务","permalink":"https://intlouis.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://intlouis.github.io/tags/SpringCloud/"},{"name":"Sentinel","slug":"Sentinel","permalink":"https://intlouis.github.io/tags/Sentinel/"},{"name":"gateway","slug":"gateway","permalink":"https://intlouis.github.io/tags/gateway/"},{"name":"限流算法","slug":"限流算法","permalink":"https://intlouis.github.io/tags/%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95/"},{"name":"OpenFeign","slug":"OpenFeign","permalink":"https://intlouis.github.io/tags/OpenFeign/"},{"name":"Nacos","slug":"Nacos","permalink":"https://intlouis.github.io/tags/Nacos/"}]}