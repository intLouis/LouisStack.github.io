{"meta":{"title":"Welcome!","subtitle":"嘿嘿","description":"就职于不知名小公司，无事来此放放屁","author":"Louis","url":"https://intlouis.github.io","root":"/"},"pages":[{"title":"分类","date":"2022-03-25T17:40:40.000Z","updated":"2022-03-26T08:01:58.961Z","comments":true,"path":"categories/index.html","permalink":"https://intlouis.github.io/categories/index.html","excerpt":"","text":""},{"title":"关于我","date":"2022-03-25T17:45:27.000Z","updated":"2022-03-27T07:39:36.790Z","comments":true,"path":"about/index.html","permalink":"https://intlouis.github.io/about/index.html","excerpt":"","text":"菜鸟一个而已"},{"title":"友链","date":"2022-03-18T01:49:42.000Z","updated":"2022-03-18T01:50:45.199Z","comments":true,"path":"link/index.html","permalink":"https://intlouis.github.io/link/index.html","excerpt":"","text":""},{"title":"标签😄","date":"2022-03-25T17:39:45.000Z","updated":"2022-03-26T08:02:29.473Z","comments":true,"path":"tags/index.html","permalink":"https://intlouis.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Redis基础浅谈（一）","slug":"Redis你了解多少？讲讲？","date":"2022-05-19T15:57:22.000Z","updated":"2022-06-15T04:31:00.216Z","comments":true,"path":"2022/05/19/Redis你了解多少？讲讲？/","link":"","permalink":"https://intlouis.github.io/2022/05/19/Redis%E4%BD%A0%E4%BA%86%E8%A7%A3%E5%A4%9A%E5%B0%91%EF%BC%9F%E8%AE%B2%E8%AE%B2%EF%BC%9F/","excerpt":"","text":"基本数据结构String非常常见的一个数据结构。String是一个可变的字符串结构，称之为动态字符串(Simple Dynamic String 简称 SDS)，内部实现更像一个ArrayList，内部维护着一个数组。 并且会额外预留一定的空间，减少频繁地去分配内存。 Redis的内存分配机制是这样： 当字符串的长度小于 1MB时，每次扩容都是加倍现有的空间。 如果字符串长度超过 1MB时，每次扩容时只会扩展 1MB 的空间。 Redis中字符串的结构如下： 123456struct SDS&#123; T capacity; //数组容量 T len; //实际长度 byte flages; //标志位,低三位表示类型 byte[] content; //数组内容&#125; String的应用场景就非常丰富了，例如存放一个标志位、计数等等。 listziplist也称为压缩链表，其结构如下： 12345678910111213struct ziplist&lt;T&gt;&#123; int32 zlbytes; //压缩列表占用字节数 int32 zltail_offset; //最后一个元素距离起始位置的偏移量,用于快速定位到最后一个节点 int16 zllength; //元素个数 T[] entries; //元素内容 int8 zlend; //结束位 0xFF&#125;//entries中的内容struct entry &#123; int&lt;var&gt; prevlen; // 前一个 entry 的字节长度 int&lt;var&gt; encoding; // 元素类型编码 optional byte[] content; // 元素内容&#125; ziplist连锁更新问题由于ziplist中的entry 每一个存储节点（entry）都是一个zlentry (zip list entry)。 每一个entry都存储一个prevlen表示前一节点的长度。但是当prevlen 的值超过253，则prevlen会进行扩容到5字节，所以需要重新分配空间。如下面一种情况： 假设存在一个压缩列表，其包含e1、e2、e3、e4…..，假设每个节点的大小为253字节，此时在e1、e2之间插入一个长度为1的entry，这样会导致e2的prevlen长度变为254，会发生扩容到5个字节。此时，开始了连锁更新反应，那e3的prevlen代表e2的长度，由于e2长度增大了4个字节，超过了253，所以e3的prevlen也会增大4个字节，导致e3整体增大4字节从而达到257字节，导致e4……，这样连锁下去。 当然这样是非常极端的情况。 这样会导致访问的性能下降，并且分配空间这个动作也会带来一定的开销，如果是全部连锁更新，这个开销将成倍数放大。 其插入、删除操作都是以时间复杂度O（1）完成。可以使用头插法、尾插法向链表中添加元素。 压缩列表是列表键和哈希键底层实现的原理之一，「压缩列表并不是以某种压缩算法进行压缩存储数据，而是它表示一组连续的内存空间的使用，节省空间」，压缩列表的内存结构图如下： previous_entry_ength表示前一个节点entry的长度，可用于计算前一个节点的其实地址，因为他们的地址是连续的。 encoding：这里保存的是content的内容类型和长度。 content：content保存的是每一个节点的内容。 quicklist 当元素比较少时，使用ziplist存储，当任意一个条件不满足时，Redis将采用quicklist。 这么做的主要原因是，当元素长度较小时，采用ziplist可以有效节省存储空间，但ziplist的存储空间是连续的，当元素个数比较多时，修改元素时，必须重新分配存储空间，这无疑会影响Redis的执行效率，故而采用一般的双向链表。 其结构就是每一个几点都有前驱、后继指针，并且每一个节点都由一个ziplist进行组成。 先来到一个经典问题：Redis为什么快？这是一个面试常见的八股文，但是要答得全面还得组织一下语言。 Redis是一个基于内存的非关系型数据库，读写速度相较于在磁盘上存储数据的MySQL是非常快的，因为在内存中没有磁盘IO的开销。 同时，Redis的读写线程是单线程，相较于多线程，没有线程之间上下文切换的开销。 Redis在每秒钟可以完成100W个请求，所以CPU不是Redis的瓶颈，所以读写线程也没有必要使用多线程。Redis的瓶颈在于内存或者网络带宽。 采用IO多路复用的机制，能够处理大量的请求，提高了并发效率。 IO多路复用是什么？ /O 指的是网络 I/O， 多路指的是多个 TCP 连接（如 Socket），复用指的是复用一个或多个线程。I/O 多路复用的核心原理就是不再由应用程序自己来监听连接，而是由服务器内核替应用程序监听。 先介绍几种常见的IO模型。 阻塞IO在这种场景下，需要给每一个客户端创建一个连接来处理请求。不管这个客户端的连接是否有在做事，都要持续维护这个连接，直到连接断开。 在这种场景下，是难以支持大量的连接的，同时也难以支持高并发。 非阻塞IO这种模式下，服务端会不断的轮询内核数据是否准备好，如果数据没有准备好，就返回一个BWOULDBLOCK错误。这个返回值返回以后，服务端就会去轮询下一个socket，直至轮询到准备好的数据的socket。 但是这种方式同时也会造成大量的CPU资源消耗。 伪代码如下： 123456789101112Socket socket = serverSocket.accept(); // 不断轮询内核，哪个 socket 的数据是否准备好了 while (true) &#123; data = socket.read(); if (data != BWOULDBLOCK) &#123; // 表示获取数据成功 doSomething(); &#125;&#125; 多路复用IO这里以Linux系统为例，有三种，分别是select，poll，epoll。 大致可以描述为：首先都会对一组文件描述符进行相关事件的注册，然后阻塞等待某些事件的发生或等待超时。 selectselect的调用会阻塞到有文件描述符可以进行IO操作或被信号打断或者超时才会返回。意思是，只有过滤出可以进行操作的文件描述符、或者信号被打断（断开连接）、超时，这三种情况下，select才会返回。 其实就是将文件描述符分为三组，每一组监听不同的IO操作： readfds（读操作文件描述符） writefds（写操作文件描述符） exceptfds（需要进行异常处理的文件描述符） 实现方式： 将已连接的socket都放进一个文件描述符集合，使用BitsMap来表示。 调用select函数将文件描述符集合拷贝到内核里，这里发生了一个用户态和内核态的转换。 在内核中对文件描述符集合进行检查是否有网络事件产生。检查方式就是遍历这个集合，检查到有时间产生则对这个socket进行标记（可读、可写）。 将这个文件描述符集合再拷贝回用户态，用户态再遍历该集合查找可读或可写的Socket，然后执行真正的读写操作。 select可同时监听的文件描述符数量是通过FS_SETSIZE来限制的，在Linux系统中，该值为1024，当然我们可以增大这个值，但随着监听的文件描述符数量增加，select的效率会降低。 poll与select的区别在于，文件描述符是以链表的形式传入。突破了BitsMap的长度限制，当然会受到系统限制。 epollepoll在内核中使用红黑树来维护进程所有待检测的文件描述符，把需要监控的sokcet通过epoll_ctl() 函数加入内核中的红黑树里，红黑树时间复杂度是O(logn)，这样不需要像select和poll那样每次传入所有的待检测socket集合，大大节省了数据拷贝和内存分配的开销。 epoll是事件驱动，内核中维护了一个链表记录就绪事件。当某个socket有事件发生时，通过回调函数将其加入就绪事件列表中，当用户调用epoll_wait()时，只会返回有事件发声描述符的个数，不会将所有socket全部返回，大大提高了效率。 图片来自https://xiaolincoding.com/（个人感觉小林coding讲的最好） 边缘触发和水平触发这张图可以说是非常形象了，边缘触发状态由0变1时触发，水平触发则是持续地触发。 使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次，所以要保证程序一次性将内核缓冲区的数据全部读取完毕。 用水平触发模式时，当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取。 举例：你的快递被放到了一个快递箱里，如果快递箱只会通过短信通知你一次，即使你一直没有去取，它也不会再发送第二条短信提醒你，直到你下一个快递到来才会发送第二次。这个方式就是边缘触发；如果快递箱发现你的快递没有被取出，它就会不停地发短信通知你，直到你取出了快递，它才消停，这个就是水平触发的方式。 存在问题： 若轮询的将数据读完，对方给我们发9.5k的数据，我们采取每次读取1k的方式进行轮询读取，在读完9k的时候，下一次我们读到的数据为0.5k，我们就知道缓冲区中数据已经读完了就停止本次轮询。但还有一种情况，对方给我们发的数据为10k,我们采取每次读取1k的方式轮询的读取数据，当我们已经读取了10k的时候，并不知道有没有数据了，我们仍旧还要尝试读取数据，这时read()就被阻塞了。 解决方案： 如果使用边缘触发模式，I/O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。 因此，我们会循环从文件描述符读写数据，如果文件描述符是阻塞的，假如说最后一次没有数据可以读写，那么这个进程将会阻塞，又由于是单线程，程序将会阻塞住。 所以，这种循环读取的过程是不能够被阻塞的，不然会影响到整个程序的运行。所以边缘触发模式一般和非阻塞 I/O 搭配使用，如果说最后无数据可读，系统会返货错误，错误类型为EAGAIN或EWOULDBLOCK。 总结一般来说水平触发，内核会时刻通知你是否有数据可读，在编程上出错可能性相较于边缘触发更小，同事保证了数据的完整性。 但是这种频繁地内核态与用户态、以及数据频繁拷贝，占用了大量cpu资源和内存资源，效率来讲也是比较低的。 而边缘触发，明显的效率更高，一次性读出全部数据，避免了多次读取的开销。但是难以保证数据完整，不能及时取出所有的数据。 但是配合非阻塞IO来使用，可以解决这个问题。 多路复用真的让我学傻了，搞了一晚上，才大概搞明白，操作系统还是太菜了/(ㄒoㄒ)/~~。 Redis之Reactor模型我们知道，Redis作为一个单线程，它是如何处理如此之多的TCP连接的？ 不同于多线程，每次来一个连接请求，就创建一个线程连接，但是Redis的设计是无法做到这样的。 Redis的高吞吐量，是基于Reactor设计模式，由一个非阻塞的线程接受所有TCP请求，将这些请求交给文件事件分派器，每个TCP请求会有不同的动作，比如连接、读取、写入等等。这些动作都是有对应的不同的事件处理器，最后由事件处理器来处理这些请求。 这里“多路”指的是多个网络连接客户端，“复用”指的是复用同一个线程(单进程)。 可以看出，文件事件处理器（file event handler）主要是包含 4 个部分，如图所示： 多个 socket（客户端连接） IO 多路复用程序（支持多个客户端连接的关键） 文件事件分派器（将 socket 关联到相应的事件处理器） 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） Redis的持久化机制AOF图片来自小林coding 如下图，AOF机制如下。 图片清晰的说明，Redis在执行写入命令时，会将日志以追加的方式写入到AOF（Append Only File）日志文件。 AOF中记录的内容如下：*3代表命令有三个部分，每个部分都是【$+数字】开头，后面紧跟具体的命令、键或值。数字则代表命令或者值的字节数。 有个细节，就是先写为什么要先进行写操作再写日志呢？ 原因就是Redis是单线程，所以如果先写日志，阻塞住了，那写操作也迟迟不执行。 还有就是避免额外的检查开销，日志是不会进行语法检查的，很有可能将错误的日志也写入进去了，如果先执行写操作，就避免了这个问题，因为写操作会对语法进行检查。假如说记录了错误日志，Redis使用数据恢复时，就会出错。 AOF存在的问题AOF与MySQL的bin log、redo log相似，写入到AOF文件的频率由参数控制。 Redis执行完写操作命令，将命令写入到AOF缓冲区，经过系统调用，写入操作系统内核缓冲区，最后操作系统调用fsync()写入到 硬盘中。 简单介绍三种策略 在 redis.conf 配置文件中的 appendfsync 配置项可以有以下 3 种参数可填： Always，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘； Everysec，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘； No，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。 AOF 重写机制Redis的AOF日志文件会随着Key的不断写入、修改，会变得越来越庞大。 其很大一部分的日志，是对同一个键值对的重复修改，即使这个键值对在Redis中已经删除了，AOF日志依旧会把所有的操作记录下来，这样AOF日志会变得庞大且冗余。 此时，就出现了AOF重写机制。重写就是将Redis中键值对的最新值进行记录，先重新生成一个AOF日志，再替换原来冗余的AOF日志。 这里说一下为什么重写 AOF 的时候，不直接复用现有的 AOF 文件，而是先写到新的 AOF 文件再覆盖过去。 因为如果 AOF 重写过程中失败了，现有的 AOF 文件就会造成污染，可能无法用于恢复使用。 AOF后台重写Redis是单线程，如果其中键值对非常多，那么很有可能阻塞线程。这个过程是非常耗时的，不能放在主线程中进行。 Redis 的重写 AOF 过程是由后台子进程 bgrewriteaof 来完成的，这么做有以下好处： 主线程可以继续处理请求，避免阻塞。 子进程有主进程的数据副本，注意，这是两个进程，主进程和子进程。不用子线程的目的很简单，不会造成同一个内存中的数据共享而产生的写锁竞争，从而导致开销变大。 而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式，而当父子进程任意一方修改了该共享内存，就会发生「写时复制」，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。 子进程是怎么拥有主进程一样的数据副本的呢？ 主进程在通过 fork 系统调用生成 bgrewriteaof 子进程时，操作系统会把主进程的「页表」复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。 由于主进程和子进程的的物理空间指向同一个，且都是只读权限。 当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，于是触发页异常中断。 缺页中断是由于违反权限导致的，然后操作系统会在「缺页异常处理函数」里进行物理内存的复制，并重新设置其内存映射关系，将父子进程的内存读写权限设置为可读写，最后才会对内存进行写操作，这个过程被称为「**写时复制(Copy On Write)**」。 写时复制，顾名思义就是，在发生写操作的时候，操作系统才回去复制物理内存。 而采用写时复制就大大减少了这样的开销。只有在主进程修改了键值对时，才会发生COW，注意这里只会复制主进程修改的物理内存数据，没修改物理内存还是与子进程共享的。 为什么采用COW？ 之所以不采用直接全量拷贝父进程物理内存的方式，就是因为这样的开销是十分巨大的，会导致Redis无法处理其他请求。 重写AOF过程中，主进程的键值对被修改导致父子进程中这个键值对数据不一致，怎么办？ 为了解决这种数据不一致问题，Redis 设置了一个 AOF 重写缓冲区，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。 在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」。 也就是说，在 bgrewriteaof 子进程执行 AOF 重写期间，主进程需要执行以下三个工作: 执行客户端发来的命令； 将执行后的写命令追加到 「AOF 缓冲区」； 将执行后的写命令追加到 「AOF 重写缓冲区」； 当子进程完成 AOF 重写工作（扫描数据库中所有数据，逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志）后，会向主进程发送一条信号，信号是进程间通讯的一种方式，且是异步的。 主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作： 将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致； 新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。 信号函数执行完后，主进程就可以继续像往常一样处理命令了。 RDBRedis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行： 执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，会阻塞主线程； 执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以避免主线程的阻塞； 尽管 RDB 比 AOF 的数据恢复速度快，但是快照的频率不好把握： 如果频率太低，两次快照间一旦服务器发生宕机，就可能会比较多的数据丢失； 如果频率太高，频繁写入磁盘和创建子进程会带来额外的性能开销。 那有没有什么方法不仅有 RDB 恢复速度快的优点和，又有 AOF 丢失数据少的优点呢？ 当然有，那就是将 RDB 和 AOF 合体使用，这个方法是在 Redis 4.0 提出的，该方法叫混合使用 AOF 日志和内存快照，也叫混合持久化。 当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。 也就是说，使用了混合持久化，AOF 文件的前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据。 这样的好处在于，重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样加载的时候速度会很快。 加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得数据更少的丢失。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://intlouis.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://intlouis.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"锁","slug":"锁","permalink":"https://intlouis.github.io/tags/%E9%94%81/"},{"name":"Redis","slug":"Redis","permalink":"https://intlouis.github.io/tags/Redis/"},{"name":"NoSql","slug":"NoSql","permalink":"https://intlouis.github.io/tags/NoSql/"}]},{"title":"MySQL（1）——四大特性以及隔离级别的实现","slug":"MySQL（1）——四大特性以及隔离级别的实现","date":"2022-05-15T05:11:16.000Z","updated":"2022-05-17T16:20:03.473Z","comments":true,"path":"2022/05/15/MySQL（1）——四大特性以及隔离级别的实现/","link":"","permalink":"https://intlouis.github.io/2022/05/15/MySQL%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94%E5%9B%9B%E5%A4%A7%E7%89%B9%E6%80%A7%E4%BB%A5%E5%8F%8A%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E7%9A%84%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"本文以MySQL的InnoDB为例讲解四大特性（原子性、隔离性、一致性、持久性）以及四大隔离级别的实现。 两种日志bin logbin log可以抽象地理解成SQL语句，以二进制的形式记录对数据修改的逻辑日志。常用于数据同步，数据恢复等。 binlog是mysql的逻辑日志，并且由Server层进行记录，使用任何存储引擎的mysql数据库都会记录binlog日志。 binlog刷盘 binlog会在特定的时机进行刷盘，刷盘时机由sync_binlog参数来设定。刷盘即将事务commit到内存中的数据写入磁盘。 sync_binlog参数值如下： 0：每次事务commit，会将数据写入系统的page cache中，会将由系统自行判断何时写入磁盘； 1：每次commit的时候都要将binlog写入磁盘； N：每N个事务都commit，才会将binlog写入磁盘。 不同的参数带来系统性能影响是不一样的，参数为0则性能较高，但是存在数据一致性和持久性的问题。参数为1，最大限度保证数据的安全性，但是频繁刷盘带来性能下降问题。参数为N，则需要视业务场景进行设置，需要在性能与数据安全之间做一个权衡。 但一般情况下，基于保守考虑，参数默认设置为1，保证数据的安全。 redo logredo log包括两部分：一个是内存中的**日志缓冲(redo log buffer)，另一个是磁盘上的日志文件(redo log file)**，mysql每执行一条DML语句，先将记录写入redo log buffer，后续某个时间点再一次性将多个操作记录经过操作系统缓存（os buffer）通过调用函数fsync写到redo log file，完成持久化。 这种先写日志，再写磁盘的技术就是MySQL里经常说到的WAL(Write-Ahead Logging) 技术。在持久化一个数据页之前，先将内存中相应的日志页持久化。 同理，redo log的写入磁盘时机也有参数innodb_flush_log_at_trx_commit设置 参数为0时，1秒前的数据都在redo log buffer中，并没有写入到os buffer，有宕机数据丢失的风险，但是性能较高。 参数为1时，是commit的同时写入到os buffer并且调用fsync写入磁盘（redo log file）。 参数为2时，每次提交都写入到os buffer，这样MySQL服务宕机也不会造成数据丢失，但是如果是断电，也会导致数据丢失。 redo log记录的数据的变更，redo log实际上记录数据页的变更，而这种变更记录是没必要全部保存，因此redo log实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志。 当数据罗盘后，redo log的数据会被覆盖。 整体来看，redo log的存在是为了临时提交到内存的数据不丢失而设计。这也是**Write-Ahead Log(预先日志持久化)**的实现，先将数据以redo log file的形式持久化后，等数据真正写入磁盘（data）后，才算一次事务真正的持久化完成。redo log为事务持久化提供了提高了可靠性。 如下图所示： bin log 和 redo log的区别 bin log redo log 文件大小 可通过参数配置每个文件的大小 每个redo log 的大小是固定的，循环写入。 实现方式 Server层面实现的，所有引擎都可以适用bin log日志 InnoDB引擎层面实现的，不是所有引擎都有 记录方式 通过追加的方式记录，当文件超过设定值，则会新建一个文件继续追加。 采用循环写的方式， 适用场景 崩溃恢复 主从复制以及数据恢复。 bin log 以及 redo log存在的意义bin log 与 redo log 是相辅相成的存在，bin log 记录了几乎全量的逻辑日志，保证断电宕机后的数据恢复。而redo log 是为当前一次事务持久化提供保障，两者同时配合，才能将数据安全性达到最高。 两阶段提交什么是crash-safe能力？我们知道redo log，保证了MySQL宕机后恢复数据的能力。 即使宕机，重启后系统会自动检查redo log，将未写入到MySQL的数据从redo log中恢复到MySQL中去。 两阶段提交两阶段提交实际上也是最大限度地保证宕机后数据可以重新恢复。 主要过程如下图: 执行器调用存储引擎接口，存储引擎将修改更新到内存中后，将修改操作写到redo log里面，此时redo log处于prepare状态； 存储引擎告知执行器执行完毕，执行器开始将操作写入到bin log中，写完后调用存储引擎的接口提交事务； 存储引擎将redo log的状态置为commit。 为什么需要两阶段提交？bin log其中之一的功能就是恢复数据，如误删数据，就需要从bin log中恢复。 为了保证Bin log 和redo log上的数据一致。 假设redo log和binlog分别提交，可能会造成用日志恢复出来的数据和原来数据不一致的情况。 假设先写redo log再写binlog，即redo log没有prepare阶段，写完直接置为commit状态，然后再写binlog。那么如果写完redo log后Mysql宕机了，重启后系统自动用redo log 恢复出来的数据就会比binlog记录的数据多出一些数据，这就会造成磁盘上数据库数据页和binlog的不一致，下次需要用到binlog恢复误删的数据时，就会发现恢复后的数据和原来的数据不一致。 假设先写binlog再写redolog。如果还未写redo log 而且Mysql宕机了。那当前事务无效，但是binlog上的记录就会比磁盘上数据页的记录多出一些数据出来，下次用binlog恢复数据，就会发现恢复后的数据和原来的数据不一致。 简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。 四大特性原子性：事务为最小的执行单位，不可再分，一个事物要么全部成功，要么全部失败。 隔离性：多个事务并发执行时，事物之间是互相独立不影响的。 一致性：数据前后合法，这个不做过多讲解，与编码和业务强相关。 持久性：事务提交后，它的修改应当是永久的，即使数据库宕机也不会对其有影响。 原子性的实现undo log 数据库事务四大特性中有一个是原子性，具体来说就是 原子性是指对数据库的一系列操作，要么全部成功，要么全部失败，不可能出现部分成功的情况。 实际上，原子性底层就是通过undo log实现的。undo log主要记录了数据的逻辑变化，比如一条INSERT语句，对应一条DELETE的undo log，对于每个UPDATE语句，对应一条相反的UPDATE的undo log，这样在发生错误时，就能回滚到事务之前的数据状态 持久性的实现当数据修改时，除了修改Buffer Pool中的数据，还会在redo log记录这次操作；当事务提交时，会调用fsync接口对redo log进行刷盘。如果MySQL宕机，重启时可以读取redo log中的数据，对数据库进行恢复。redo log采用的是WAL（Write-ahead logging，预写式日志），所有修改先写入日志，再更新到Buffer Pool，保证了数据不会因MySQL宕机而丢失，从而满足了持久性要求。 redo log在上面有详细的介绍，此处就不过多赘述。 一致性的实现概念描述：一致性是指事物执行结束后，数据库的完整性没有被破坏，事务执行的前后都是合法的数据状态。数据库的完整性包括但是不限于：实体完整性（如行的主键存在且唯一）列完整性（如字段的类型，大小，长度符合要求），外键约束（外键约束还存在）用户自定义完整性（如转账前后，两个账户的和应该是不变的） 可以说，一致性是事物追求的最终目标，前面提到的原子性，隔离性，持久性都是为了保证数据库的一致性。此外除了数据库底层的保障，一致性的实现也需要应用层的保障。 保证原子性、持久性和隔离性，如果这些特性无法保证，事务的一致性也无法保证 数据库本身提供保障，例如不允许向整形列插入字符串值、字符串长度不能超过列的限制等 应用层面进行保障，例如如果转账操作只扣除转账者的余额，而没有增加接收者的余额，无论数据库实现的多么完美，也无法保证状态的一致 隔离性的实现（重点）隔离性追求的是并发情形下事务之间不会相互干扰，简单起见，我们仅考虑最简单的读操作和写操作(暂时不考虑带锁读等特殊操作)，那么隔离性的探讨，主要可以分为两个方面： (一个事务)写操作对(另一个事务)写操作的影响：锁机制保证隔离性 (一个事务)写操作对(另一个事务)读操作的影响：MVCC保证隔离性 总的来说，隔离性是由MVCC+锁机制来实现。 锁机制按照粒度，分为表锁与行锁：MyISAM 支持表锁，InnoDB 支持表锁和行级锁，默认是行级锁。表级锁：开销小，加锁快，不会出现死锁。锁定粒度大，发送锁冲突的概率比较高，并发处理效果较低。行级锁： 开销大，加锁慢，会出现死锁，锁定粒度较大，发生锁冲突的概率会小一点，并发处理的效果高 事务并发问题有T1，T2两个事务。 脏读：T1读取到T2修改但未提交的数据，但T2又回滚了，此时T1读取的就是无效的脏数据。 幻读：T1查询到的结果集后，T2增加一条数据，这条数据恰好满足T1的查询条件，当T1再次使用相同条件查询，会发现两次查询结果集数量不一致。好似发生了幻觉。 不可重复读：事务中可以查询到别的事务当前提交的数据，即可能发声两次同样的查询返回不一样的结果集。 MySQL四种隔离级别读未提交 事务可以读到其他事务修改但未提交的数据，此隔离级别会发生脏读、幻读、不可重复度等并发问题。 读已提交 只能看到其他事务已经提交的数据，此隔离级别会发生不可重复、幻读度问题。 可重复读 解决了脏读问题，同一个事务多次查询同一数据结果一致。但是并未解决幻读问题。 串行化 是最高的隔离级别，通过强制事务串行化执行，避免了前面所说到的幻读的问题。就是可串行化 会在读取的每一行数据上都加上锁，但是这样会导致超时和锁争用问题。 MVCC 在早期的数据库中，只有读读之间的操作才可以并发执行，读写，写读，写写操作都要阻塞，这样就会导致MySQL的并发性能极差。 采用了MVCC机制后，只有写写之间相互阻塞，其他三种操作都可以并行，这样就可以提高了MySQL的并发性能。 ReadViewReadView可以理解为数据库中某一个时刻所有未提交事务的快照。ReadView有几个重要的参数： m_ids：表示生成ReadView时，当前系统正在活跃的读写事务的事务Id列表。 min_trx_id：表示生成ReadView时，当前系统中活跃的读写事务的最小事务Id。 max_trx_id：表示生成ReadView时，当前时间戳InnoDB将在下一次分配的事务id。 creator_trx_id：当前事务id。 所以当创建ReadView时，可以知道这个时间点上未提交事务的所有信息。 隐藏列InnoDB存储引擎中，它的聚簇索引记录中都包含两个必要的隐藏列，分别是： trx_id：事务Id，每次一个事务对某条聚簇索引记录进行改动时，都会把该事务的事务id赋值给trx_id隐藏列。 roll_pointer：回滚指针，每次对某条聚簇索引记录进行改动时，都会把旧的版本写入到undo log中，然后这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息。 版本链假如数据初始状态如下 数据第一次被修改时： 数据第二次被修改时： 由图可知，每一次修改回滚指针都会指向相应的undo_log。 实现机制在四个隔离级别中，读未提交是没有进行版本控制的。而串行化则是严格遵守先后顺序执行事务，不需要进行版本控制。 而读已提交和可重复读这两个隔离级别则使用到了MVCC。下面就来展开说说。 读已提交的实现 在这个隔离级别中，当前事务是可以读取到所有事物已经提交的修改，即，所有事物提交的修改对所有事务可见。 每次查询都会生成一个ReadView，若在当前事务中查询，则会查询到最新已提交的修改。 由于每次查询都会生成readview，即每一次查询的数据都可能不一样，所以不可避免会有不可重复读的问题。 只要解决了不可重复读的问题，就达到了可重复读这个隔离级别。 如何解决？ 可重复读的实现 关键就在于，在可重复读的这个隔离级别下，只会在事务开始后第一次读取数据时生成一个 Read View 所以在一个事务中，只有唯一一个ReadView，所以从始至终它读取到的数据都是一致的。无 论在此过程中其他事务是否提交，当前事务可见的数据只有一个版本，即开启事务读取的版本。 详细原理参照本篇文章： https://javaguide.cn/database/mysql/innodb-implementation-of-mvcc.html#mvcc-%E8%A7%A3%E5%86%B3%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB%E9%97%AE%E9%A2%98 解决幻读问题我们知道，幻读是两次读取的结果集数量不一致。 当前读它读取的数据库记录，都是当前最新的版本，会对当前读取的数据进行加锁，防止其他事务修改数据。是悲观锁的一种操作。 如下操作都是当前读： select lock in share mode (共享锁) select for update (排他锁) update (排他锁) insert (排他锁) delete (排他锁) 串行化事务隔离级别 快照读快照读的实现是基于多版本并发控制，即MVCC，既然是多版本，那么快照读读到的数据不一定是当前最新的数据，有可能是之前历史版本的数据。 如下操作是快照读： 不加锁的select操作（注：事务级别不是串行化） 在普通SELECT的操作中，会使用生成一次ReadView的方式来防止幻读。 2、执行 select…for update/lock in share mode、insert、update、delete 等当前读 在当前读下，读取的都是最新的数据，如果其它事务有插入新的记录，并且刚好在当前事务查询范围内，就会产生幻读！InnoDB 使用 Next-key Lock 来防止这种情况。当执行当前读时，会锁定读取到的记录的同时，锁定它们的间隙，防止其它事务在查询范围内插入数据。只要我不让你插入，就不会发生幻读。 next-key lock可以理解为行锁+间隙锁。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://intlouis.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://intlouis.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"https://intlouis.github.io/tags/MySQL/"},{"name":"锁","slug":"锁","permalink":"https://intlouis.github.io/tags/%E9%94%81/"}]},{"title":"消息中间件（1）——之Kafka","slug":"MQ-kafka","date":"2022-04-23T14:09:45.000Z","updated":"2022-05-12T14:39:17.819Z","comments":true,"path":"2022/04/23/MQ-kafka/","link":"","permalink":"https://intlouis.github.io/2022/04/23/MQ-kafka/","excerpt":"","text":"讲完微服务四大基本组件以后，接下来会发布消息中间件的系列文章，所以第一篇的话选择介绍Kafka。 言归正传 以经典的电商秒杀场景，设想10000件商品在几秒内被秒杀抢购完，我们如何保证在这么短的时间内扛下如此之高的并发，如果机器性能较差，上千甚至上万的QPS直接打在机器上，tomcat线程池一定会被打满，引发生产事故。 此时就需要用到消息中间件，无论有多少请求，统统暂存至MQ，然后服务器慢慢消费，既保证了消息不丢失，也大大减轻了机器的压力。 MQ是高并发场景下常用的中间件，这样的场景一定会依赖MQ，同时MQ也常会用于服务之间的数据同步。 基本术语消息：Kafka 中的数据单元被称为消息，也被称为记录，可以把它看作数据库表中某一行的记录。记录可以是用户发起的http请求。 主题（Topic）：消息的种类称为 主题,可以说一个主题代表了一类消息。相当于是对消息进行分类。主题就像是数据库中的表。 分区（partition）：同一个主题中的分区均匀分布在机器集群，这样可以更好实现服务器集群组的负载均衡。 分区的作用就是让消费者集群中的节点都能消费到同一个topic的消息，假如没有分区，那topicA部署在其中一个节点上，这个节点服务器的压力就会很大，而分区是让消费者集群中都部署topicA，这样消费者就会均匀的把消息发送到每个topicA下。 相当于创建了n个文件夹去存储这些消息。不会把所有的消息都放在一个文件夹里。 生产者（Producer）：MQ中非常重要的概念，向主题（topic）发送消息的就是生产者。 消费者（Consumer）：MQ中非常重要的概念，订阅主题（topic）消息的客户端就是消费者，用于处理生产者产生的消息。 偏移量：偏移量（Consumer Offset）是一种元数据，它是一个不断递增的整数值，用来记录消费者发生重平衡（Rebalance）时的位置，以便用来恢复数据。 broker: 一个独立的 Kafka 服务器就被称为 broker，broker 接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。 broker 集群：broker 是集群 的组成部分，broker 集群由一个或多个 broker 组成，每个集群都有一个 broker 同时充当了集群控制器的角色（自动从集群的活跃成员中选举出来）。 重平衡（Rebalance）：试想，消费组集群中某个实例节点挂掉以后，其他消费者实例自动重新分配topic分区的过程。实现了Kafka的消费端高可用。 Kafka特性高吞吐、低延迟：kakfa 最大的特点就是收发消息非常快，kafka 每秒可以处理几十万条消息，它的最低延迟只有几毫秒。 高伸缩性： 每个主题(topic) 包含多个分区(partition)，主题中的分区可以分布在不同的主机(broker)中。 持久性、可靠性： Kafka 能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失，Kafka 底层的数据存储是基于 Zookeeper 存储的，Zookeeper 我们知道它的数据能够持久存储。 容错性： 允许集群中的节点失败，某个节点宕机，Kafka 集群能够正常工作 高并发： 支持数千个客户端同时读写 Kafka 的消息队列模式 一班消息队列模式分为两种：点对点，发布-订阅者模式。 点对点应该很好理解，就是一个生产者对应一个消费者。 如果是多个生产者对应多个消费者，即生产者集群—消费者集群这样子，就是发布订阅者模式。发布订阅者模式也是设计模式之一，同时也是MQ的核心设计思想之一。 图中所示，一个Kafka集群包含若干个broker、producer、和consumer。 Kafka通过zk管理集群配置，从而选举leader。在consumer发生变化时（例如某个实例挂掉）进行Rebalance。 四个核心APIProducer API，它允许应用程序向一个或多个 topics 上发送消息记录 Consumer API，允许应用程序订阅一个或多个 topics 并处理为其生成的记录流 Streams API，它允许应用程序作为流处理器，从一个或多个主题中消费输入流并为其生成输出流，有效的将输入流转换为输出流。 Connector API，它允许构建和运行将 Kafka 主题连接到现有应用程序或数据系统的可用生产者和消费者 Kafka 为何如此之快 话不多说，Kafka以高性能、高吞吐量、高并发而闻名，下面介绍一下Kafka的零拷贝与批量、顺序写入。 零拷贝广义上的零拷贝，意思就是减少不必要的拷贝次数，并不是真正的不需要拷贝。而减少了不必要的拷贝次数，那就是减少了拷贝次数，提高传输效率，同时也省去了CPU切换上下文的时间。 前景提要：DMA（Direct Memory Access） 直接内存访问（Direct Memory Access），是一种硬件设备绕开CPU独立直接访问内存的机制。所以DMA在一定程度上解放了CPU，把之前CPU的杂活让硬件直接自己做了，提高了CPU效率。 目前支持DMA的硬件包括：网卡、声卡、显卡、磁盘控制器等。 是一种允许外围设备（硬件子系统）直接访问系统主内存的机制。也就是说，基于 DMA 访问方式，系统主内存于硬盘或网卡之间的数据传输可以绕开 CPU 的全程调度。目前大多数的硬件设备，包括磁盘控制器、网卡、显卡以及声卡等都支持 DMA 技术。 只有CPU参与的数据传输时，CPU将参与全局的I/O操作，有不小的上下文切换开销、等待数据读取拷贝时间开销等等。如图： 引入DMA后，CPU将从这些操作中解放出来，这些操作将有DMA来完成，而CPU可以并行地去做别的事情。 这样在大部分时间里，CPU 计算和 I/O 操作都处于并行操作，使整个计算机系统的效率大大提高。 我直接偷一张图来说明应用读写磁盘时，数据拷贝的过程： 图中可知，普通的数据交互，会发生CPU的上下文切换和用户态到内核态的转换。 这样是会对整个数据交互带来一定的开销，一般来说这是正常开销，但在成千上万次数据交互的过程中，这样的开销会占用很大一部分时间。 读数据过程： 应用程序要读取磁盘数据，调用read()函数从而实现用户态切换内核态，这是第1次状态切换； DMA控制器将数据从磁盘拷贝到内核缓冲区，这是第1次DMA拷贝； CPU将数据从内核缓冲区复制到用户缓冲区，这是第1次CPU拷贝； CPU完成拷贝之后，read()函数返回实现用户态切换用户态，这是第2次状态切换； 写数据过程： 应用程序要向网卡写数据，调用write()函数实现用户态切换内核态，这是第1次切换； CPU将用户缓冲区数据拷贝到内核缓冲区，这是第1次CPU拷贝； DMA控制器将数据从内核缓冲区复制到socket缓冲区，这是第1次DMA拷贝； 完成拷贝之后，write()函数返回实现内核态切换用户态，这是第2次切换； 所以有没有一种情况，应用不对数据做处理，那这样还有什么必要进入到应用的缓冲区呢？ 此时，零拷贝出现了。 零拷贝的实现手段，有mmap+write、sendfile、sendfile+DMA收集、splice等，在此着重讲解前二者。 2022.04.25 马不停蹄学习中…… mmapmmap是Linux提供的一种内存映射文件方法。 使用mmap会将内核空间中的读缓冲区（read buffer）的地址，与用户空间（user buffer）进行映射，从而实现内核缓冲区与程序内存的共享。 省去了将数据从内核空间拷贝到用户空间这个开销，但是仍然需要将数据copy到内核的写缓冲区 mmap 主要的用处是提高 I/O 性能，特别是针对大文件。对于小文件，内存映射文件反而会导致碎片空间的浪费，因为内存映射总是要对齐页边界，最小单位是 4 KB，一个 5 KB 的文件将会映射占用 8 KB 内存，也就会浪费 3 KB 内存。 sendfileLinux内核版本2.1中被引入。主要建立了两个文件之间的传输通道。 通过 sendfile 系统调用，数据可以直接在内核空间内部进行 I/O 传输，从而省去了数据在用户空间和内核空间之间的来回拷贝。 与mmap不同的是，对于用户而言，senfile是不可见的，但是可以感知到的。 用户会用senfile而发起数据传输，同时传输结束后会得到结果，但并不知道数据传输的过程，因为senfile不会经历到用户空间。 零拷贝讲了这么多，涉及过多的计算机组成原理和操作系统知识，不明白的同学可以去了解一下这部分的基础。 Kafka消息发送 其消息发送有几种模式，简单消息发送、同步消息发送、异步消息发送。 简单消息发送 代码中生产者(producer)的 send() 方法需要把 ProducerRecord 的对象作为参数进行发送，ProducerRecord 有很多构造函数，这个我们下面讨论， 这里调用的是ProducerRecord，这个构造函数，需要传递的是 topic主题，key 和 value。 1234567ProducerRecord&lt;String,String&gt; record = new ProducerRecord&lt;String, String&gt;(&quot;CustomerCountry&quot;,&quot;West&quot;,&quot;France&quot;);producer.send(record);public ProducerRecord(String topic, K key, V value) &#123;&#125; 从其架构图可知，生产者调用send方法后，会将消息写入分区的缓冲区中，分批次发给 broker。 同步发送消息 同步就不用过多赘述了，就是生产者调用send()消息后，会再调用get()方法等待Kafka响应。如果服务器返回错误，get()方法会抛出异常。 反之，会返回一个RecordMetadata 对象。 生产者（KafkaProducer）在发送的过程中会出现三类错误： 重试错误，这类错误可以通过重发消息来解决。 连接的错误，可以通过再次建立连接来解决； 无主错误则可以通过重新为分区选举首领来解决。 KafkaProducer 被配置为自动重试，如果多次重试后仍无法解决问题，则会抛出重试异常。另一类错误是无法通过重试来解决的，比如消息过大对于这类错误，KafkaProducer 不会进行重试，直接抛出异常。 异步发送消息 同步的弊端不用我多说了吧，发送完必须等待消息返回后才进行下一个消息的发送，效率低下，但是如果你并不关心消息返回值，那用异步发送再合适不过了。 123456789101112ProducerRecord&lt;String, String&gt; producerRecord = new ProducerRecord&lt;String, String&gt;(&quot;CustomerCountry&quot;, &quot;Huston&quot;, &quot;America&quot;); producer.send(producerRecord,new DemoProducerCallBack());//异步回调class DemoProducerCallBack implements Callback &#123; public void onCompletion(RecordMetadata metadata, Exception exception) &#123; if(exception != null)&#123; exception.printStackTrace();; &#125; &#125;&#125; 异步调用的话会有消息回调，如果消息返回了错误，需要手动对错误进行处理。 分区机制 partition代表分区，分区就是topic的分区。即topic会分成若干个区，然后该topic的会使用分区的策略来存储消息。 由于消息是存在主题（topic）的分区（partition）中的，所以当 Producer 生产者发送产生一条消息发给 topic 的时候，你如何判断这条消息会存在哪个分区中呢？ 分区策略分区策略是可以自定义的，详细请参考Kafka官方文档。下面主要介绍几个默认的分区策略。 上图是分区的集群架构，一般来说，Broker集群中每一个broker都有相同的分区，如broker1中有topicA-p0，topicA-p1，topicB-p0，topicB-p1。而这一套分区在Broker2中也有，虎屋 顺序轮询顺序分配，消息是均匀的分配给每个 partition，即每个分区存储一次消息。就像下面这样 顺序轮训策略是 Kafka Producer 提供的默认策略。 按照 key 进行消息保存这个策略也叫做 key-ordering 策略，Kafka 中每条消息都会有自己的key，一旦消息被定义了 Key，那么你就可以保证同一个 Key 的所有消息都进入到相同的分区里面，由于每个分区下的消息处理都是有顺序的，故这个策略被称为按消息键保序策略，如下图所示 闲谈一下，最近工作强度一下子上来了，导致每天都挺累的，不知道是不是工作太认真了😄 重平衡当有消费者群组申请加入或者退出的时候，会触发重平衡。 重平衡会将分区均匀分摊给各个消费者（Rebalance），这是Kafka高可用和高伸缩的基础，可以在运行的过程中移除或添加消费者。 但是在重平衡期间，会发生Stop the world（详细参照JVM Full GC），即消费者无法读取到消息，整个消费者会处于不可用的状态。 详细流程在消费者端，重平衡分为两个步骤：分别是加入组和等待领导者消费者（Leader Consumer）分配方案。这两个步骤分别对应两类特定的请求：JoinGroup 请求和 SyncGroup 请求。 当组内成员加入组时，它会向协调者发送 JoinGroup 请求。在该请求中，每个成员都要将自己订阅的主题上报，这样协调者就能收集到所有成员的订阅信息。一旦收集了全部成员的 JoinGroup 请求后，协调者会从这些成员中选择一个担任这个消费者组的领导者。领导者消费者的任务是收集所有成员的订阅信息，然后根据这些信息，制定具体的分区消费分配方案。 选出领导者之后，协调者会把消费者组订阅信息封装进 JoinGroup 请求的响应体中，然后发给领导者，由领导者统一做出分配方案后,领导者向协调者发送 SyncGroup 请求，将刚刚做出的分配方案发给协调者。 其他成员也会向协调者发送 SyncGroup 请求，只不过请求体中并没有实际的内容。这一步的主要目的是让协调者接收分配方案，然后统一以 SyncGroup 响应的方式分发给所有成员，这样组内所有成员就都知道自己该消费哪些分区了。 如下图所示 场景一：新成员加入当协调者收到新的 JoinGroup 请求后，它会通过心跳请求响应的方式通知组内现有的所有成员，强制它们开启新一轮的重平衡。具体的过程和之前的客户端重平衡流程是一样的。 场景二：成员主动离组消费者实例所在线程或进程调用 close() 方法主动通知协调者它要退出。这个场景就涉及到了第三类请求：LeaveGroup 请求。协调者收到 LeaveGroup 请求后，依然会以心跳响应的方式通知其他成员 场景三：组成员崩溃离组他和成员主动离组的区别是它属于被动离开，broker端不知道成员离组，经过心跳超时后，判定成员离组的一种情况。 流程摘自https://juejin.cn/post/6992195021910835230 重平衡的三种默认策略range策略主要是基于范围的思想。 它将单个topic的所有分区按照顺序排列，然后把这些分区划分成固定大小的分区段并依次分配给每个consumer。 round-robin策略则会把所有topic的所有分区顺序摆开，然后轮询式地分配给各个consumer。 sticky策略有效地避免了上述两种策略完全无视历史分配方案的缺陷，采用了“有黏性”的策略对所有consumer实例进行分配，可以规避极端情况下的数据倾斜并且在两次rebalance间最大限度地维持了之前的分配方案。 通常意义上认为，如果group下所有consumer实例的订阅是相同的，那么使用round-robin会带来更公平的分配方案，否则使用range策略的效果更好。 关于策略详细可以参考这篇文章：https://zhuanlan.zhihu.com/p/86718818 讲的是真滴详细👍 2022.05.09更新 订阅-发布模式实现Kafka是基于订阅-发布模式，生产者发送消息给Broker，那消费者是如何知道生产者发送了数据呢？ 此处实现订阅-发布者模式，需要消费者定期轮询Kafka Broker，对订阅的topic分区中检索消息，如果有就用来消费，没有就继续轮询下去。 12345678910111213141516try &#123; while (true) &#123; ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(100)); for (ConsumerRecord&lt;String, String&gt; record : records) &#123; int updateCount = 1; if (map.containsKey(record.value())) &#123; updateCount = (int) map.get(record.value() + 1); &#125; map.put(record.value(), updateCount); &#125; &#125;&#125;finally &#123; consumer.close();&#125; 提交和偏移量概念有一个特殊的主题**_consumer_offset**，此主题会保存每次发送消息中分区的偏移量，这个主题主要是防止消息丢失。 当重平衡后，消费者会被重新分配分区，_consumer_offset中记录下重平衡前的最后一次提交的偏移量。 重平衡后，会以上次提交的偏移量位置为起点，进行消费。如图所示，即使当前处理消息为8，但是最后一次提交的偏移量为2，所以重平衡后还是会从2开始消费。 注意，这样可能会导致重复消费，但是同时保证了消息不丢失，只需要做好幂等处理即可。 如果提交的偏移量大于最后一次消费时的偏移量，那么处于两个偏移量中间的消息将会丢失 自动提交如果enable.auto.commit设置为了true，那么默认每过5s，消费者端会自动将轮询拉取下来的消息最大的偏移量提交上去。 自动提交存在的问题： 如果消费并处理完毕，但是还没来得及提交offset，消费者宕机，当消费者重新拉起，就会从上一次提交的offset处进行消费，就会重复消费了。 如果提交了当前最新offset，而消息又没有处理完成，此时消费者又宕机了。但是重新拉起消费者以后，会从最新的offset开始消费，导致宕机前没处理完成的消息丢失。 手动提交手动提交即为处理完成后回调提交，同时手动提交也分为异步提交和同步提交。也可以异步+同步组合的方式提交。 同步提交 手动提交失败后会一直重试，直到重试成功，或者遇到无法重试的情况才结束，这样虽说能够最大限度的保证消息不丢失，但是同时在重试的过程中也阻塞了线程，限制了吞吐量。 手动同步提交应用在对消息丢失容忍度较低的情况下，以此最大限度的额保证消息不丢失。 异步提交 异步提交不会阻塞线程，但同时也不会进行重试，可以配合回调函数在提交失败的时候记录错误信息。 组合提交 对于常规性、阶段性的手动提交，我们调用 commitAsync() 避免程序阻塞，而在 Consumer 要关闭前，我们调用 commitSync() 方法执行同步阻塞式的位移提交，以确保 Consumer 关闭前能够保存正确的位移数据。将两者结合后，我们既实现了异步无阻塞式的位移管理，也确保了 Consumer 位移的正确性。 Kafka ACK 机制当生产者发送给Broker消息时，会有一个ack机制，ack有三种级别。默认为ack = 1。 acks = 0表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息。性能最高，但是最容易丢消息。对数据丢失不敏感的情况可以用这种。 acks = 1至少要等待leader已经成功将数据写入本地log，但是不需要等待所有follower是否成功写入。就可以继续发送下一条消息。这种情况下，如果follower没有成功备份数据，而此时leader又挂掉，则消息会丢失。 acks = -1或all这意味着leader需要等待所有备份(配合min.insync.replicas（最少同步副本数）使用)都成功写入日志，这种策略会保证只要有一个备份存活就不会丢失数据。这是最强的数据保证。一般除非是金融级别，或跟钱打交道的场景才会使用这种配置。当然如果min.insync.replicas配置的是1则也可能丢消息，跟acks=1情况类似。 retries，客户端发送失败，重试次数（默认：2147483647，即Integer.MAX_VALUE）。如果设置为0，只要发送消息失败，这笔消息就丢失了 Kafka应用与生产上的一些问题重复消费重复消费是非常常见的生产问题，一般发生在消息处理过后但没来得及向broker提交最新的offset，消费者就宕机了。此时提交给broker的offset还是上一次的 在重新启动该消费者以后，会从上一次提交处开始消费。 解决方案 1、一些超时后会出发Rebalance的参数可以设置更加合理（大一点），防止因超时而出发重试。 2、去重表。在消费端的Redis或者MySql保存【当前从broker拉取消息批次的ID】，查询是否已经处理过，处理过则跳过。 3、做幂等处理。 消息丢失消息丢失，会发生在生产者端、Broker端、消费者端。 生产者端丢失 当ack =0，即不需要等待broker回复确认收到的消息，就可以继续发送下一条。这种情况易造成消息丢失，如broker宕机，消费者这边还在持续发送消息。 当ack = 1，即至少等待leader节点写入到本地后，才返回消息给生产者端。 但是存在一种情况，leader将消息写入本地，返回确认收到给生产者端后，在没有来得及同步给follower，宕机，这种情况会造成消息丢失。 Broker端丢失 unclean.leader.election.enable 配置true broker端配置允许选举ISR以外的副本作为leader,会导致数据丢失，默认为false。producer发送异步消息完，只等待lead写入成功就返回了，leader crash了，这时ISR中没有follower，leader从OSR中选举，因为OSR中本来落后于Leader造成消息丢失。 关于Kafka集群 系统的高可用、高吞吐必然离不开集群，kafka也是一样的，下面讲述Kafka集群的结构设计。 现在有一个topicA，分成了2个分区，放在三台服务器上。我们知道，主要进行消息读写的是leader分区，所以我们尽量要保证leader均匀分布在各个broker上，这样就算broker宕机后，也不会对Kafka集群的可用性造成很大的冲击。 比如，我们有3个Broker，2个分区分别有2个备份（一共是3组相同的分区），每个分区的leader在一个broker只能有一个，这样保证了集群的高可用。 同时topicB、topicC都遵循这样的原则，这就是集群的意义所在，让服务更加的高可用，提高系统容错性，同时就是需要占用不小的资源。","categories":[{"name":"微服务","slug":"微服务","permalink":"https://intlouis.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"-消息队列 -Kafka","slug":"消息队列-Kafka","permalink":"https://intlouis.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-Kafka/"}]},{"title":"微服务浅谈（四）——限流、熔断之Sentinel","slug":"SpringCloud——限流、熔断之Sentinel","date":"2022-04-07T14:52:06.000Z","updated":"2022-04-16T08:49:23.937Z","comments":true,"path":"2022/04/07/SpringCloud——限流、熔断之Sentinel/","link":"","permalink":"https://intlouis.github.io/2022/04/07/SpringCloud%E2%80%94%E2%80%94%E9%99%90%E6%B5%81%E3%80%81%E7%86%94%E6%96%AD%E4%B9%8BSentinel/","excerpt":"","text":"摆烂了几天，没有更新博客，写博客真是非常耗费脑力的事情。 言归正传，今天介绍SpringCloud的第四大组件——Sentinel 提醒：Sentinel内容比较多嗷~ 服务器雪崩 什么是服务器雪崩？顾名思义，我们知道雪崩可以是很小的波动导致，例如你对着雪山大吼一声，也有可能导致雪崩。 类比到系统中，一个很小的“波动”，例如有一条sql是慢查询，假设这样一个场景，你的系统重启完毕，大量用户涌入，每个用户都会调用到这个存在慢查询的接口，那这一下会将tomcat线程全部打满，导致所有的线程全部hold住，其他接口无法创建请求，整个系统处于崩溃状态。 这就是由于慢查询导致的雪崩。 在微服务中，当一个服务A不可用，会造成调用A服务的服务也发生大量线程hold住，形成连锁效应，导致整个微服务系统崩坏。 雪崩对于客户端也是可感知的，当客户端发起请求后，迟迟得不到返回结果，这就是客户端的雪崩表现。原因就是线程池已经爆满，或者接近爆满。 当然，在实际生产环境中，导致雪崩的原因有很多，为了防止雪崩，我们引入Sentinel对流量过大的接口进行熔断。 Sentinel实质上是给予了系统更大的容错性，即使服务发生故障，也可以及时地切断服务调用链路或进行降级，这样一定程度的保证了系统的高可用，增强系统的健壮性。 对商用系统而言，系统宕机是非常严重的事故，基本都是在P1级别起步，宕机过程中不仅存在数据丢失，损失更是按照秒来计算，所以系统容错是非常重要的，宁愿服务部分可用，也不能完全挂掉。 解决方案常见的容错思路有隔离、超时、限流、熔断、降级这几种。 隔离非常容易理解，假设服务A有100个线程，我们各分配30个给B、C、D服务，即使其中一个或多个服务宕机，也不会影响其他服务的调用。 超时 在上游服务调用下游服务的时候，设置一个最大响应时间，如果超过这个时间，下游未作出反应，就断开请求，释放掉线程。 但是超时时间需要斟酌设置，如果设置过大，也容易产生线程堆积。如果设置过小，则有些请求正常执行，却返回稍慢，导致请求被中断，数据无法返回，造成用户体验下降。 限流 限流，就是限制系统流量，包含进入系统的流量以及输出的流量，当流量打到设置的阈值，就需要开启相应的限流措施，在下面会详细讲到。 熔断 熔断机制是一种级别较高的保证系统高可用的无奈之举，当下游的系统因为某种原因导致服务器压力过大导致的响应变慢，此时上游系统继续调用该系统容易导致下游系统的雪崩效应，进而可能导致整个系统崩溃。 所以熔断就出现了：暂时停止对下游系统的调用。这样保证了当前系统的高可用，但是存在了局部不可用，这就是牺牲局部保全整体的措施。 服务熔断一般有三种状态： 熔断关闭状态（Closed）：服务没有故障时，熔断器所处的状态，对调用方的调用不做任何限制。 熔断开启状态（Open）：后续对该服务接口的调用不再经过网络，直接执行本地的fallback方法。 半熔断状态（Half-Open）：尝试恢复服务调用，允许有限的流量调用该服务，并监控调用成功率。如果成功率达到预期，则说明服务已恢复，进入熔断关闭状态；如果成功率仍旧很低，则重新进入熔断关闭状态。 降级 降级其实就是为服务提供一个兜底方案，一旦服务无法正常调用，就使用兜底方案。 比如当前服务不可用了，那我就切换到备用节点等等。 Sentinel各种相关规则 Sentinel的各种相关规则是实现精细化系统高可用的基础。 细颗粒的规则制定可以让系统的高可用更加灵活，让系统故障影响范围缩减至尽可能小。 Sentinel流量控制规则首先流控是以资源为单位，即接口请求地址。 流量控制，原理是监控当前资源QPS或并发线程数指标，避免被突发流量冲击系统造成系统波动。保证系统的高可用。 资源名：唯一名称，默认是请求路径，可自定义。 针对来源：指定对哪个微服务进行限流，默认指default，意思是不区分来源，全部限制。 阈值类型/单机阈值： QPS（每秒请求数量）: 当调用该接口的QPS达到阈值的时候，进行限流。 线程数：当调用该接口的线程数达到阈值的时候，进行限流。 关联流控模式某些资源存在争抢现象，例如两个接口修改同一个字段，抢占资源只会降低系统吞吐量，所以需要施加流控。 关联流控模式指的是，当指定接口关联的接口达到限流条件时，开启对指定接口开启限流。 链路流控模式对调用资源的链路进行监控，比如 1.在OrderService中添加一个queryGoods方法，不用实现业务2.在OrderController中，改造/order/query端点，调用OrderService中的queryGoods方法(/order/query -&gt; queryGoods)3.在OrderController中添加一个/order/save的端点，调用OrderService的queryGoods方法(/order/save -&gt; queryGoods) 两者都是调用queryGoods这个方法，但是可以监控其中一个调用链路，当调用链路达到阈值，则对该链路进行流控。 流控效果 快速失败（默认）: 直接失败，抛出异常，不做任何额外的处理，是最简单的效果。 Warm Up：它从开始阈值到最大QPS阈值会有一个缓冲阶段，一开始的阈值是最大QPS阈值的 1/3，然后慢慢增长，直到最大阈值，适用于将突然增大的流量转换为缓步增长的场景。 排队等待：让请求以均匀的速度通过，单机阈值为每秒通过数量，其余的排队等待； 它还会让设 置一个超时时间，当请求超过超时间时间还未处理，则会被丢弃。 Sentinel降级规则 降级规则有三个衡量指标，慢调用比例、异常响应比例、异常数。 慢调用比例: 选择以慢调用比例作为阈值，需要设置允许的慢调用 RT（即最大的响应时间），请求的响应时间大于该值则统计为慢调用。当单位统计时长内请求数目大于设置的最小请求数目，并且慢调用的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求响应时间小于设置的慢调用 RT 则结束熔断，若大于设置的慢调用 RT 则会再次被熔断。 探测恢复状态（HALF-OPEN 状态）：在此状态下，在接下来的设置的时间之内都不会调用真实方法，直接走降级方法。 异常比例: 当单位统计时长内请求数目大于设置的最小请求数目，并且异常的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。异常比率的阈值范围是 [0.0, 1.0]，代表 0% - 100%。 异常数：当单位统计时长内的异常数目超过阈值之后会自动进行熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断 如图所示： 上面配置表示，如果在1S之内,有【超过1个的请求】且这些请求中【响应时间&gt;最大RT】的【请求数量比例&gt;10%】，就会触发熔断。 比如: 最大RT=900,比例阈值=0.1,熔断时长=10,最小请求数=10 情况1: 1秒内的有20个请求，只有10个请求响应时间&gt;900ms, 那慢调用比例=0.5，这种情况就会触发熔断。 情况2: 1秒内的有20个请求，只有1个请求响应时间&gt;900ms, 那慢调用比例=0.05，这种情况不会触发熔断。 情况3: 1秒内的有8个请求，只有6个请求响应时间&gt;900ms, 那慢调用比例=0.75，这种情况不会触发熔断，因为最小请求数这个条件没有满足。 Sentinel热点规则Sentinel还可以对热点数据数据进行监控和限流，比如某个接口的订单参数调用量特别容易突发增长。 1234567891011@RestController@Slf4jpublic class HotSpotController &#123; @RequestMapping(&quot;/hotSpot1&quot;) @SentinelResource(value = &quot;hotSpot1&quot;) public String hotSpot1(Long productId)&#123; log.info(&quot;访问编号为:&#123;&#125;的商品&quot;,productId); return &quot;hotSpot1&quot;; &#125;&#125; 新增一个热点规则：如图意义为监控hotSpot1这个接口的请求情况。 因为我们就一个参数，所以参数索引是0。 新增规则参数，热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流。热点参数限流可以看做是一种特殊的流量控制，仅对包含热点参数的资源调用生效。 请求过来时，请求中的第一个参数，即productId = 1的时候，定义为了热点信息，热点信息超过阈值时，则会被限流。 系统规则 系统保护规则是从应用级别的入口流量进行控制，从单台机器的总体 Load、RT、入口 QPS 、CPU使用率和线程数五个维度监控应用数据，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 系统保护规则是应用整体维度的，而不是资源维度的，并且仅对入口流量 (进入应用的流量) 生效。 Load（仅对 Linux/Unix-like 机器生效）：当系统 load1 超过阈值，且系统当前的并发线程数超过系统容量时才会触发。 系统保护。系统容量由系统的 maxQps * minRt 计算得出。设定参考值一般是 CPU cores * 2.5。 RT：当单台机器上所有入口流量的平均 RT 达到阈值即触发系统保护，单位是毫秒。 线程数：当单台机器上所有入口流量的并发线程数达到阈值即触发系统保护。 入口 QPS：当单台机器上所有入口流量的 QPS 达到阈值即触发系统保护。 CPU使用率：当单台机器上所有入口流量的 CPU使用率达到阈值即触发系统保护。 Sentinel规则持久化我们知道，这些规则是存储在内存中的。一旦服务器重启，就会消失，所以持久化我们的自定义规则，应该都是基本操作。 这个Sentinel Dashboard类似控制台，就是我们操作的可视化界面。 如图所示为Sentinel持久化规则的流程图。 @SentinelResource的使用 @SentinelResource 用于定义资源，并提供可选的异常处理和 fallback 配置项。主要参数如下： 属性 作用 value 资源名称，必需项（不能为空） entryType entry 类型，可选项（默认为 EntryType.OUT） blockHandler/blockHandlerClass blockHandler 对应处理 BlockException 的函数名称，可选项。blockHandler 函数访问范围需要是 public，返回类型需要与原方法相匹配，参数类型需要和原方法相匹配并且最后加一个额外的参数，类型为 BlockException。blockHandler 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 blockHandlerClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。 fallback/fallbackClass fallback 函数名称，可选项，用于在抛出异常的时候提供 fallback 处理逻辑。fallback 函数可以针对所有类型的异常（除了 exceptionsToIgnore 里面排除掉的异常类型）进行处理。fallback 函数签名和位置要求： 1. 返回值类型必须与原函数返回值类型一致； 2.方法参数列表需要和原函数一致，或者可以额外多一个 Throwable 类型的参数用于接收对应的异常。 3.fallback 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 fallbackClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。 defaultFallback 默认的 fallback 函数名称，可选项，通常用于通用的 fallback 逻辑（即可以用于很多服务或方法）。默认 fallback 函数可以针对所有类型的异常（除了 exceptionsToIgnore 里面排除掉的异常类型）进行处理。若同时配置了 fallback 和 defaultFallback，则只有 fallback 会生效。defaultFallback 函数签名要求： 1. 返回值类型必须与原函数返回值类型一致； 2. 方法参数列表需要为空，或者可以额外多一个 Throwable 类型的参数用于接收对应的异常。 3. defaultFallback 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 fallbackClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。 exceptionsToIgnore 用于指定哪些异常被排除掉，不会计入异常统计中，也不会进入 fallback 逻辑中，而是会原样抛出。 Sentinel是默认与MVC兼容的，也就是说普通的的接口是默认会接入监控的，但一些其他方法，不是通过Controller进行调用的资源。你也想监控此类资源，则需要加上SentinelResource进行监控。 Sentinel的总结到这里就告一段落，微服务四大主要组件都已分享完毕，后面会更新一些生产问题的处理过程、思考过程。不过也不一定嘿嘿嘿，🤭","categories":[],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://intlouis.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://intlouis.github.io/tags/SpringCloud/"},{"name":"Sentinel","slug":"Sentinel","permalink":"https://intlouis.github.io/tags/Sentinel/"}]},{"title":"微服务浅谈（三）——Gateway网关","slug":"SpringCloud-网关","date":"2022-03-27T16:39:32.000Z","updated":"2022-04-07T14:53:18.460Z","comments":true,"path":"2022/03/28/SpringCloud-网关/","link":"","permalink":"https://intlouis.github.io/2022/03/28/SpringCloud-%E7%BD%91%E5%85%B3/","excerpt":"","text":"所有请求必经之门——网关Nginx与Gateway的区别SpringCloud Gateway作为网关，其作用和Nginx是有区别的。 1、Gateway和Nginx可以取其一进行使用，也可以两个都使用，具体是看系统结构和业务需求，这个很重要。 2、Gateway更加贴近业务层面，因为它可以在截到请求后执行一些鉴权、过滤、断言等，做一些基本的流控。 3、Nginx更多是作为流量的总入口，负载均衡等。 4、Nginx支持Lua脚本，但是其始终是需要进行二次开发，扩展性不如Gateway。 SpringCloud Gateway 更加靠近业务。 假设系统结构是： Ng-&gt;Gateway-&gt;业务层，那么Ng只是作为一个流量入口的作用，并没有接触到业务。而Gateway可以将请求路由到服务端（某一微服务）。 Gateway 可以与Nacos集成，通过拉取Nacos中注册中心的地址，通过拉取到的地址进行转发，这样避免了将请求地址写死在配置中。同时，也会在转发请求的时候遵循你设置好的Ribbon负载均衡策略。 Gateway几个基本信息 id：路由标识符，区别于其他 Route。 uri：路由指向的目的地 uri，即客户端请求最终被转发到的微服务。 order：用于多个 Route 之间的排序，数值越小排序越靠前，匹配优先级越高。 predicate：断言的作用是进行条件判断，只有断言都返回真，才会真正的执行路由。 filter：过滤器用于修改请求和响应信息。 predicate：断言，用于进行条件判断，只有断言都返回真，才会真正的执行路由。 将这几个参数理解即可，会在配置文件中使用到。 过滤器过滤器的生命周期： 1、PRE：这种过滤器会在请求被路由前，即转发请求前会执行过滤器中编写的逻辑代码。我们一般会用这种过滤器进行身份验证、挑选服务实例、日志追踪、请求者信息记录等等。 2、POST：这种过滤器会在请求路由到服务后，执行相应逻辑代码。这种过滤器可用来为响应添加标准的HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等。 两种Filter：GatewayFilter与GlobalFilter，顾名思义，一个是局部过滤，一个是全局过滤。 局部过滤器局部过滤器提供的API的功能一般来说可以满足大部分的需求了： 过滤器工厂 作用 参数 AddRequestHeader 为原始请求添加Header Header的名称及值 AddRequestParameter 为原始请求添加请求参数 参数名称及值 AddResponseHeader 为原始响应添加Header Header的名称及值 DedupeResponseHeader 剔除响应头中重复的值 需要去重的Header名称及去重策略 Hystrix 为路由引入Hystrix的断路器保护 HystrixCommand 的名称 FallbackHeaders 为fallbackUri的请求头中添加具体的异常信息 Header的名称 PrefixPath 为原始请求路径添加前缀 前缀路径 PreserveHostHeader 为请求添加一个preserveHostHeader=true的属性，路由过滤器会检查该属性以决定是否要发送原始的Host 无 RequestRateLimiter 用于对请求限流，限流算法为令牌桶 keyResolver、 rateLimiter、 statusCode、 denyEmptyKey、 emptyKeyStatus RedirectTo 将原始请求重定向到指定的URL http状态码及重定向的url RemoveHopByHopHeadersFilter 为原始请求删除IETF组织规定的一系列Header 默认就会启用，可以通过配置指定仅删除哪些Header RemoveRequestHeader 为原始请求删除某个Header Header名称 RemoveResponseHeader 为原始响应删除某个Header Header名称 RewritePath 重写原始的请求路径 原始路径正则表达式以及重写后路径的正则表达式 RewriteResponseHeader 重写原始响应中的某个Header Header名称，值的正则表达式，重写后的值 SaveSession 在转发请求之前，强制执行WebSession::save操作 无 secureHeaders 为原始响应添加一系列起安全作用的响应头 无，支持修改这些安全响应头的值 SetPath 修改原始的请求路径 修改后的路径 SetResponseHeader 修改原始响应中某个Header的值 Header名称，修改后的值 SetStatus 修改原始响应的状态码 HTTP 状态码，可以是数字，也可以是字符串 StripPrefix 用于截断原始请求的路径 使用数字表示要截断的路径的数量 Retry 针对不同的响应进行重试 retries、statuses、methods、series RequestSize 设置允许接收最大请求包的大小。如果请求包大小超过设置的值，则返回 413 Payload Too Large 请求包大小，单位为字节，默认值为5M ModifyRequestBody 在转发请求之前修改原始请求体内容 修改后的请求体内容 ModifyResponseBody 修改原始响应体的内容 修改后的响应体内容 自定义局部过滤器 自定义局部过滤器很好理解，相信各位都写过拦截用户请求进行鉴权的拦截器，网关其实也是这么一个原理，只不过网关远远比我们自己写的拦截器功能更加丰富。 重点：名称是有固定格式【xxxGatewayFilterFactory】，这个很重要，关系到后面的配置类中的编写。 举例，我要打印每个接口的耗时： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@Componentpublic class TimeGatewayFilterFactory extends AbstractGatewayFilterFactory&lt;TimeGatewayFilterFactory.Config&gt; &#123; private static final String BEGIN_TIME = &quot;beginTime&quot;; //构造函数 public TimeGatewayFilterFactory() &#123; super(TimeGatewayFilterFactory.Config.class); &#125; //读取配置文件中的参数 赋值到 配置类中 @Override public List&lt;String&gt; shortcutFieldOrder() &#123; return Arrays.asList(&quot;show&quot;); &#125; @Override public GatewayFilter apply(Config config) &#123; return new GatewayFilter() &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; if (!config.show)&#123; // 如果配置类中的show为false，表示放行 return chain.filter(exchange); &#125; exchange.getAttributes().put(BEGIN_TIME, System.currentTimeMillis()); /** * pre的逻辑 * chain.filter().then(Mono.fromRunable(()-&gt;&#123; * post的逻辑 * &#125;)) */ return chain.filter(exchange).then(Mono.fromRunnable(()-&gt;&#123; Long startTime = exchange.getAttribute(BEGIN_TIME); if (startTime != null) &#123; System.out.println(exchange.getRequest().getURI() + &quot;请求耗时: &quot; + (System.currentTimeMillis() - startTime) + &quot;ms&quot;); &#125; &#125;)); &#125; &#125;; &#125; @Setter @Getter static class Config&#123; private boolean show; &#125;&#125; 配置文件如下，因为我们的逻辑类名是TimeGatewayFilterFactory 所以其配置key就是Time=true/false，本例子转载于掘金大佬博客 1234567891011121314151617181920212223242526272829server: port: 9000spring: application: name: api-gateway cloud: nacos: discovery: server-addr: 127.0.0.1:8848 gateway: discovery: locator: enabled: true # 让gateway可以发现nacos中的微服务 routes: - id: product_route # 路由的名字 uri: lb://product-service # lb指的是从nacos中按照名称获取微服务,并遵循负载均衡策略 predicates: - Path=/product-serv/** # 符合这个规定的才进行1转发 filters: - StripPrefix=1 # 将第一层去掉 - id: order_route uri: lb://order-service predicates: - Path=/order-serv/** filters: - StripPrefix=1 - Time=true 全局过滤全局过滤，只需集成GlobalFilter即可编写自定义逻辑代码，无需其余的配置。 123456789101112131415@Componentpublic class AuthGlobalFilter implements GlobalFilter &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; String token = exchange.getRequest().getQueryParams().getFirst(&quot;token&quot;); if (StringUtils.isBlank(token)) &#123; System.out.println(&quot;鉴权失败&quot;); exchange.getResponse().setStatusCode(HttpStatus.UNAUTHORIZED); return exchange.getResponse().setComplete(); &#125; return chain.filter(exchange); &#125;&#125; 除此之外默认有几种全局过滤器。 2022/03/31补充： 通过与明新讨论，Gateway的吞吐量优化，自己上网查阅部分资料，补充以下内容： 常见的限流算法1、计数器算法 这个算法很好理解，设定一个阈值，如K = 100，则在单位时间内，超过这个阈值的请求全部都将被拒绝。 这个算法很粗暴，个人觉得没有什么应用价值，因为其存在很大的弊端，举例： 如果我设定，一分钟内只能通过500的请求，可以认为服务器在一分钟内最多能处理500请求。 那么存在两个周期的零界点，就是这一分钟的请求在前55秒处理了100个请求，剩下400个请求集中在最后5秒，如果下一个一分钟的前5秒，又迎来400个请求，那么这10秒钟就处理了800个请求，远远超出了服务器单位时间内所能承受的最大请求数。 结论就是，计数器算法并不适合应对突发的峰值流量。 2、漏桶算法 漏桶算法，顾名思义，就是给桶的底部戳一个洞，这个洞漏出去水的速率是均匀的。 请求进来相当于给这个漏桶加水，无论桶里的水有多少，漏出去水的速率都是均匀的，但存在一个问题，就是水满自溢。 同时，其优势就是能够保护数据库，不让突发而来的请求全部打在db上。 但是短板也显而易见，桶的容量始终是固定的，如果到存在请求洪峰，那将会有大量的请求被”溢出“。 3、令牌桶算法 此算法是结合了漏桶算法升级而来，当请求进来，拿到令牌时才能继续往下执行。 当加入令牌的速率恒定，在请求速率较小时（低于令牌生产的速度），此时令牌可以积累一部分的令牌，从而应对突发的洪峰请求。 但是令牌也不是生产的，当令牌桶满了，生产的令牌也会被丢弃。从而最大程度的处理请求，也很好的保护了DB。 网关集成Sentinel本部分会在后续的Sentinel文章中详细讲解。","categories":[{"name":"微服务","slug":"微服务","permalink":"https://intlouis.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://intlouis.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://intlouis.github.io/tags/SpringCloud/"},{"name":"gateway","slug":"gateway","permalink":"https://intlouis.github.io/tags/gateway/"},{"name":"限流算法","slug":"限流算法","permalink":"https://intlouis.github.io/tags/%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95/"}]},{"title":"微服务浅谈（二）——服务调用&OpenFeign","slug":"SpringCloud-OpenFeign","date":"2022-03-14T16:41:15.000Z","updated":"2022-03-27T16:41:01.182Z","comments":true,"path":"2022/03/15/SpringCloud-OpenFeign/","link":"","permalink":"https://intlouis.github.io/2022/03/15/SpringCloud-OpenFeign/","excerpt":"","text":"服务调用的两种常用方式：RPC&amp;HTTPHTTP就不过多介绍了，稍微讲一下RPC的架构。 RPC架构一个完整的RPC架构里面包含了四个核心的组件，分别是Client，Client Stub，Server以及Server Stub，这个Stub可以理解为存根。 客户端(Client)，服务的调用方。 客户端存根(Client Stub)，存放服务端的地址消息，再将客户端的请求参数打包成网络消息，然后通过网络远程发送给服务方。 服务端(Server)，真正的服务提供者。 服务端存根(Server Stub)，接收客户端发送过来的消息，将消息解包，并调用本地的方法。 纵观整个过程，实际上就是客户端发起调用，然后本次调用经过Client Stub封装，发送给Server，然后Server Stub会解析发送过来的内容，并且将数据进行返回。 RPC的目标就是要把2、3、4、7、8、9这些步骤都封装起来。 RPC调用是使用自定义的数据格式进行传输，是基于原生TCP进行通信，速度较快，效率较高。 HTTP则是一种较为通用的调用方式，在跨语言上存在优势，只要提供restful风格的接口，则可以进行请求。 关于RPC与Http的技术选型：如果需要使用RPC调用，则需要服务提供方与消费方都是使用RPC调用，即需要双方使用相同的技术，如都使用Dubbo调用。 而Http则无需关注语言的实现，只需请求数据遵循restful规范即可。 如何选择？ 既然两种方式都可以实现远程调用，我们该如何选择呢？ 速度来看，RPC要比http更快，虽然底层都是TCP，但是http协议的信息往往比较臃肿 难度来看，RPC实现较为复杂，http相对比较简单 灵活性来看，http更胜一筹，因为它不关心实现细节，跨平台、跨语言。 因此，两者都有不同的使用场景： 如果对效率要求更高，并且开发过程使用统一的技术栈，那么用RPC还是不错的。 如果需要更加灵活，跨语言、跨平台，显然http更合适 那么我们该怎么选择呢？ 微服务，更加强调的是独立、自治、灵活。而RPC方式的限制较多，因此微服务框架中，一般都会采用基于Http的Rest风格服务。 RestTemplate存在的问题其实Rest存在的问题，只需要三个字概况，不够优雅（四个字），当调用服务的url拼接较多的参数时，这样的url会变得非常难以维护，这样拼接的url在实际生产中并不少见。 OpenFeign简介OpenFeign是一种可以在微服务之间实现“无感知调用“的一个中间件。 即引入这种中间件以后，各个接口之间的调用就像在单机上部署一样，无需过多的关注调用的地址和端口，这就是所谓的”无感知调用“，或许这样描述并不是非常恰当，但达意即可。 SpringMVC的注解，如@RequestMapping等等。OpenFeign的@FeignClient可以解析SpringMVC的@RequestMapping注解下的接口，并通过动态代理的方式产生实现类，实现类中做负载均衡并调用其他服务。 OpenFeign沿用SpringMVC的注解，大大地降低了学习成本，作为一个组件它是一个好组件😀 OpenFeign的底层还是使用了Ribbon，Ribbon的介绍在博客相关文章有介绍过，所以OpenFeign是一个调用+客户端负载均衡的一个微服务组件。 OpenFeign把RestTemplete，Ribbon，Hystrix糅合在了一起，在使用时就可以更加方便，优雅地完成整个服务的暴露，调用等。避免做一些重复的复制粘贴接口URL，或者重复定义接口等。还是非常值得去学习的。 但Hystrix一般由Sentinel代替了，关于Sentinel的博客文章后续会发布。 OpenFeign的简单使用 1、在启动类上增加@EnableFeignClients注解（注：以下例子来自OpenFeign官方文档） 1234567891011121314@SpringBootApplication@EnableFeignClientspublic class WebApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(WebApplication.class, args); &#125; @FeignClient(&quot;name&quot;) static interface NameService &#123; @RequestMapping(&quot;/&quot;) public String getName(); &#125;&#125; 2、StoreClient就是供消费者调用的接口，每个接口上添加MVC相应注解以及接口请求地址。一般来说会专门创建一个这样的interface以供消费者调用。 1234567891011121314@FeignClient(&quot;stores&quot;)public interface StoreClient &#123; @RequestMapping(method = RequestMethod.GET, value = &quot;/stores&quot;) List&lt;Store&gt; getStores(); @RequestMapping(method = RequestMethod.GET, value = &quot;/stores&quot;) Page&lt;Store&gt; getStores(Pageable pageable); @RequestMapping(method = RequestMethod.POST, value = &quot;/stores/&#123;storeId&#125;&quot;, consumes = &quot;application/json&quot;) Store update(@PathVariable(&quot;storeId&quot;) Long storeId, Store store); @RequestMapping(method = RequestMethod.DELETE, value = &quot;/stores/&#123;storeId:\\\\d+&#125;&quot;) void delete(@PathVariable Long storeId);&#125; 3、在消费者的Controller层，注入StoreClient这个对象，使用这个对象直接进行方法调用即可。 Feign的自定义配置日志级别： NONE：不打印任何日志。 BASIC：只记录请求方法、URL、响应状态码和执行时间 HEADERS：记录基本信息，请求和响应标题 FULL： 记录请求和响应标题、正文和行数据 还有其他的Feign自定义配置，在此就不一一赘述。","categories":[{"name":"微服务","slug":"微服务","permalink":"https://intlouis.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"OpenFeign","slug":"OpenFeign","permalink":"https://intlouis.github.io/tags/OpenFeign/"},{"name":"微服务","slug":"微服务","permalink":"https://intlouis.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://intlouis.github.io/tags/SpringCloud/"}]},{"title":"微服务浅谈（一）——Nacos","slug":"SpringCloud_Nacos","date":"2022-03-13T11:31:08.440Z","updated":"2022-03-25T18:12:30.809Z","comments":true,"path":"2022/03/13/SpringCloud_Nacos/","link":"","permalink":"https://intlouis.github.io/2022/03/13/SpringCloud_Nacos/","excerpt":"","text":"服务注册中心注册中心基本原理 在使用注册中心时，一共有三种角色：服务提供者（Service Provider）、服务消费者（Service Consumer）、注册中心（Registry）。 服务发现原理：服务发现机制就是通过一个中间件去记录服务提供者的ip地址，服务名以及心跳等数据（比如用mysql去存储这些信息），然后服务消费者会去这个中间平台去查询相关信息，然后再去访问对应的地址，这就是服务注册和服务发现。 Nacos 提供对服务的实时的健康检查，阻止向不健康的主机或服务实例发送请求。Nacos 支持传输层 (PING 或 TCP)和应用层 (如 HTTP、MySQL、用户自定义）的健康检查。 对于复杂的云环境和网络拓扑环境中（如 VPC、边缘网络等）服务的健康检查，Nacos 提供了 agent 上报模式和服务端主动检测2种健康检查模式。Nacos 还提供了统一的健康检查仪表盘，帮助您根据健康状态管理服务的可用性及流量。 服务提供者：向注册中心注册为一个服务实例，并且向外部暴露调用接口。 服务消费者：向注册中心订阅需要调用的服务，并缓存服务的实例列表再内存中。后续，Consumer 向对应服务的 Provider 发起调用时，从内存中的该服务的实例列表选择一个，进行远程调用。 注册中心：当注册的实例超过一定时间未心跳（nacos默认30s心跳一次，若下一次未收到，将不再路由请求至该实例），则注册中心判断这个服务已下线，将从服务实例列表移除。 不同的注册中心可能在实现原理上会略有差异。例如说，Eureka 注册中心，并不提供通知功能，而是 Eureka Client 自己定期轮询，实现本地缓存的更新。 当然，一个服务消费者，也可以是一个服务提供者。 nacos 作为注册中心时，Namespace + Group + Service 作为配置中心时，Namespace + Group + DataId 元数据： Nacos数据（如配置和服务）描述信息，如服务版本、权重、容灾策略、负载均衡策略、鉴权配置、各种自定义标签（label），从作用范围来看，分为服务级别的元信息、集群的元信息及实例的元信息。 Nacos1.x与Nacos2.xNacos1.x对比存在的问题 1、心跳续约是30s（默认），当服务较多时，就会有较高的TPS数。 2、心跳感知问题，心跳感知为15s无应答，即15秒未感知到应用心跳时，才能删除实例，在并发较高的情况下，降低服务的高可用。如：当服务宕机时，需要快速剔除服务实例，但需要等待15s，这样的时效性并不理想。 3、有HTTP和UDP两种数据推送的方式，与客户端需要进行全量对账（保持服务发现），会进行大量查询，导致QPS较高，这种可以理解成牺牲大量的查询来保持服务的发现，但实际生产中，所有的服务都是较为稳定的，大量的查询实际是为了那仅有的几个服务变动而设计，这样的性价比并不高。 Nacos2.x优化 1、使用长连接进行心跳续约，大大降低重复请求。同时长连接在断开时是可以快速感知到的，不需要等待15s。 2、连接反复创建存在开销，使用长连接减少了这样的开销，同时减少了TIME_WAIT的问题。 2.0架构带来的问题 相对于Tomcat HTTP短连接模型，长连接模型需要自己管理连接状态，增加了复杂性 长连接gRPC基于HTTP2.0 Stream，相对于HTTP的open API可观测性和易用性降低了 两者性能对比 具体性能分析可参照这篇博文：重磅官宣：Nacos2.0 发布，性能提升 10 倍 负载均衡服务器端负载均衡： 由中间件Ng进行路由 客户端负载均衡： 根据负载均衡规则，自行请求。 Ribbon：提供丰富的负载均衡算法。 手写一个客户端侧负载均衡器 手写负载均衡器部分代码如图： 这段代码的意思就是在实例列表中随机进行请求。这段代码只是粗略展示负载均衡的其中一个算法。 手写负载均衡器主要原理就是获取到此服务的所有url，然后以轮询、随机等方式进行调用指定的url Ribbon与Nginx的区别既然提到了负载均衡，怎么能少得了Nginx呢，Ribbon和Nginx之间的不同在于，Nginx是集中式的对接收的请求进行负载均衡，而Ribbon是在消费者端进行负载均衡，形象一点就是如下图。 NginxNginx的工作模型如下图： RibbonRibbon的工作模型如下图 Ribbon的负载均衡与Ng的负载均衡之不同就是，Ng是被动负载均衡，Ribbon是主动负载均衡。 Ribbon会在收到Http请求后，去拉取注册中心中的服务实例List，获取到List以后，会使用负载均衡策略，在List中挑选一个服务实例进行请求。 Ribbon默认是懒加载，懒加载会使项目启动速度加快，但是同时在第一次请求时，会去拉取注册中心的服务实例，以及初始化负载均衡容器，导致请求响应速度相对较慢。同时可选定服务进行配置饥饿加载。 同时Ribbon有多种负载均衡的策略模式可供选择，默认的就是同区域轮训模式：ZoneAwareLoadBalancer 是一个根据区域（Zone） 来进行负载均衡器，因为如果不同机房跨区域部署服务列表，跨区域的方式访问会产生更高的延迟，ZoneAwareLoadBalancer 就是为了解决此类问题，不过默认都是同一区域 Ribbon负载均衡策略： 策略类 命名 描述 RandomRule 随机策略 随机选择server RoundRobinRule 轮询策略 轮询选择， 轮询index，选择index对应位置的Server； RetryRule 重试策略 对选定的负载均衡策略机上重试机制，在一个配置时间段内当选择Server不成功，则一直尝试使用subRule的方式选择一个可用的server； BestAvailableRule 最低并发策略 逐个考察server，如果server断路器打开，则忽略，再选择其中并发链接最低的server AvailabilityFilteringRule 可用过滤策略 过滤掉一直失败并被标记为circuit tripped的server，过滤掉那些高并发链接的server（active connections超过配置的阈值）或者使用一个AvailabilityPredicate来包含过滤server的逻辑，其实就就是检查status里记录的各个Server的运行状态； ResponseTimeWeightedRule 响应时间加权重策略 根据server的响应时间分配权重，响应时间越长，权重越低，被选择到的概率也就越低。响应时间越短，权重越高，被选中的概率越高，这个策略很贴切，综合了各种因素，比如：网络，磁盘，io等，都直接影响响应时间 ZoneAvoidanceRule 区域权重策略 综合判断server所在区域的性能，和server的可用性，轮询选择server并且判断一个AWS Zone的运行性能是否可用，剔除不可用的Zone中的所有server","categories":[{"name":"微服务","slug":"微服务","permalink":"https://intlouis.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://intlouis.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://intlouis.github.io/tags/SpringCloud/"},{"name":"Nacos","slug":"Nacos","permalink":"https://intlouis.github.io/tags/Nacos/"}]}],"categories":[{"name":"数据库","slug":"数据库","permalink":"https://intlouis.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"微服务","slug":"微服务","permalink":"https://intlouis.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://intlouis.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"锁","slug":"锁","permalink":"https://intlouis.github.io/tags/%E9%94%81/"},{"name":"Redis","slug":"Redis","permalink":"https://intlouis.github.io/tags/Redis/"},{"name":"NoSql","slug":"NoSql","permalink":"https://intlouis.github.io/tags/NoSql/"},{"name":"MySQL","slug":"MySQL","permalink":"https://intlouis.github.io/tags/MySQL/"},{"name":"-消息队列 -Kafka","slug":"消息队列-Kafka","permalink":"https://intlouis.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-Kafka/"},{"name":"微服务","slug":"微服务","permalink":"https://intlouis.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://intlouis.github.io/tags/SpringCloud/"},{"name":"Sentinel","slug":"Sentinel","permalink":"https://intlouis.github.io/tags/Sentinel/"},{"name":"gateway","slug":"gateway","permalink":"https://intlouis.github.io/tags/gateway/"},{"name":"限流算法","slug":"限流算法","permalink":"https://intlouis.github.io/tags/%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95/"},{"name":"OpenFeign","slug":"OpenFeign","permalink":"https://intlouis.github.io/tags/OpenFeign/"},{"name":"Nacos","slug":"Nacos","permalink":"https://intlouis.github.io/tags/Nacos/"}]}